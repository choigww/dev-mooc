{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preprocessing and Generation\n",
    "### Categorical and Ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Values in ordinal features are sorted in some meaningful order.\n",
    "* Label encoding maps categories to numbers\n",
    "* Frequency encoding maps categories to their frequencies\n",
    "* Label and Frequency encodings are often used for tree-based models\n",
    "* One-hot encoding is often used for non-tree-based models\n",
    "* Interactions of categorical features can help linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "![nontree-tree](img/nontree-tree.png)\n",
    "\n",
    "#### **Alphabetical (sorted)**\n",
    "  * `sklearn.preprocessing.LabelEncoder`\n",
    "  * [S,C,Q] -> [2, 1, 3]\n",
    "  \n",
    "#### **Order of appearance**\n",
    "  * `Pandas.factorize`\n",
    "  * [S,C,Q] -> [1,2,3]\n",
    "  \n",
    "#### **Frequency encoding**\n",
    "  * [S,C,Q] -> [0.5, 0.3, 0.2]\n",
    "```python\n",
    "encoding = titanic.groupby('Embarked').size()\n",
    "encoding = encoding/len(titanic)\n",
    "titanic['enc'] = titanic.Embarked.map(encoding)\n",
    "```\n",
    "\n",
    "### Can `frequency encoding` be of help for non-tree based models?\n",
    "> \"Yes. For example, if frequency of category is correlated with target value, linear model will utilize this dependency.\"\n",
    "\n",
    "\n",
    "### One more thing about `frequency encoding` ...\n",
    "> \"If you have multiple categories with the `same frequency`, they won't be distinguishable in this new feature. We might apply or run categorization here in order to deal with such ties.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "![onehotencoding](img/one-hot-encoding.png)\n",
    "\n",
    "* works well with linear models/ knn/ neural nets.\n",
    "* already `scaled` - since minimum of this feature is zero and maximum is one.\n",
    "\n",
    "If there are too many categories in one feature, many binary columns could be created from one-hot encoding : \n",
    "* `We will add too many new binary columns with a few non-zero values.`\n",
    "\n",
    "### Sparse matrices!\n",
    "* Instead of allocating space in RAM for every element of an array, we can storeo only onn-zero values and save a lot of memory.\n",
    "* Often useful when working with categorical features or text data.\n",
    "* Most of popular libraries can work with these sparse matrices directly: `XGBoost`, `LightGBM`, `sklearn`, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "* feature interaction among several categorical features\n",
    "* useful for non-tree based model (linear, knn, neural nets)\n",
    "\n",
    "### Concatenation with binary columns\n",
    "![feature-concat](img/feature-concat.png)\n",
    "\n",
    "* Now linear models can find optimal coefficient for every interaction and improve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
