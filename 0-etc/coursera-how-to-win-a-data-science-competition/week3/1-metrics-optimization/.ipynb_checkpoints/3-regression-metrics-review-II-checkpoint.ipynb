{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics Review II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan for the video\n",
    "\n",
    "#### 1) Regression\n",
    "* MSE, RMSE, R-squared\n",
    "* MAE\n",
    "* **(R)MSPE, MAPE**\n",
    "* **(R)MSLE**\n",
    "\n",
    "\n",
    "2) Classification\n",
    "* Accuracy, LogLoss, AUC\n",
    "* Cohen's (Quadratic weighted) Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From MSE and MAE to MSPE and MAPE\n",
    "\n",
    "#### Say ...\n",
    "* We need to predict how many laptops two shops will sell\n",
    "* In the train set for a particular date, we see that the first shop sold 10 items and the second shop sold 1000 items\n",
    "\n",
    "#### Then suppose ...\n",
    "* Our model predicts 9 items intead of 10 for the first shop and 999 instead of 1000 for the second shop.\n",
    "* It could happen that **off by one error in the first case, is much more critical than in the second case**\n",
    "* **BUT `MSE` and `MAE` are equal to `one` for both shops predictions**, and thus these **offs caused by one error are indistinguishable**\n",
    "\n",
    "----\n",
    "* Shop 1 : predicted 9, sold 10, `MSE` = 1\n",
    "* Shop 2 : predicted 999, sold 1000, `MSE` = 1\n",
    "\n",
    "<br/>\n",
    "* Shop 1 : predicted 9, sold 10, `MSE` = 1\n",
    "* Shop 2 : predicted 900, sold 1000, `MSE` = 10000\n",
    "\n",
    "<br/>\n",
    "* Shop 1 : predicted 9, sold 10, relative_metric = 1\n",
    "* Shop 2 : predicted 900, sold 1000, relative_metric = 1\n",
    "----\n",
    "\n",
    "#### `MSPE` = Mean Square Percentage Error\n",
    "#### `MAPE` = Mean Absolute Percentage Error\n",
    "* `MAE` and `MSE` work with the absolute values\n",
    "*  `MSPE` and `MAPE` work with the relative values (divided by the target values)\n",
    "\n",
    "#### `MSPE` and `MAPE` can be thought as `weighted version of MAE and MSE`\n",
    "* For `MAPE`, the weight of its sample is **inversely proportional to its target**\n",
    "* For `MSPE`, the weight of its sample is **inversely proportional to a target square**\n",
    "\n",
    "#### We see the curve became more flat as the target value increases\n",
    "* It means that the cost we pay for a fixed absolute error, depends on the target value\n",
    "* As the target increases, **we pay less**\n",
    "\n",
    "![mspe-mape](../img/mspemape.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSPE : constant\n",
    "\n",
    "#### Best constant = `weighted target mean`\n",
    "* The best constant for the example below = about `6.6`\n",
    "  * we see that it's **biased towards small targets**\n",
    "  * since the absolute error for them is a weighted with the highest weight and thus inputs metrics the most\n",
    "\n",
    "\n",
    "![mspe-constant](../img/mspe-constant.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE : constant\n",
    "\n",
    "#### Best constant = `weighted target median`\n",
    "* Optimal value here = `6`\n",
    "  * even smaller than the best constant for `MSPE`\n",
    "  * BUT do not try to explain it using outliers\n",
    "    * If an outlier had an extremely small value, `MAPE` would be very biased towards it, **since the extremely small outlier will have the highest weight!**\n",
    "\n",
    "![mape-constant](../img/mape-constant.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (R)MSLE : Root Mean Square Logarithmic Error\n",
    "\n",
    "* Target value can be `0` - which leads logarithmic not to be defined.\n",
    "  * That is why a constant is usually added to the predictions and the targets before applying the logarithmic operation\n",
    "\n",
    "$$RMSLE = \\sqrt{\\frac{1}{N}\\sum^N_{i=1}((\\log{y_{i}+1})-(\\log{\\hat{y_i}+1}))^2}\\\\=RMSE((\\log{y_{i}+1}),(\\log{\\hat{y_i}+1}))\\\\\\sqrt{MSE(\\log{y_{i}+1}),(\\log{\\hat{y_i}+1})}$$\n",
    "\n",
    "\n",
    "![rmsle](../img/rmsle.png)\n",
    "\n",
    "* As it also carries about relative errors more than about absolute ones - its usecase is similar to `MSPE` and `MAPE`\n",
    "* **NOTE** the symmetry of the error curves\n",
    "  * **from the perspective of `RMSLE`, it is always better to predict more than the same amount less than target**\n",
    "* Same as RMSE does not differ much from MSE, RMSLE can be calculated without root operation\n",
    "  * But rooted version is more widely used!\n",
    "\n",
    "#### It is important to know that\n",
    "* the plot we see here on the slide is built for a version without root\n",
    "* for a root version, an analoguous plot would be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (R)MSLE : constant $\\alpha$\n",
    "\n",
    "$$RMSLE = \\sqrt{\\frac{1}{N}\\sum^N_{i=1}((\\log{y_{i}+1})-(\\log{\\alpha+1}))^2}\\\\=RMSE((\\log{y_{i}+1}),(\\log{\\alpha+1}))\\\\\\sqrt{MSE(\\log{y_{i}+1}),(\\log{\\alpha+1})}$$\n",
    "\n",
    "* Best constant **in log space** is a **mean target value**\n",
    "* We need to **exponentiate** it to get an answer\n",
    "\n",
    "![rmsle-constant](../img/rmsle-constant.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the constants\n",
    "\n",
    "Metric|Constant\n",
    "---|---\n",
    "MSE|11\n",
    "RMSLE|9.11\n",
    "MAE|8\n",
    "MSPE|6.6\n",
    "MAPE|6\n",
    "\n",
    "* `MSE` is quite biased towards the huge value from our dataset\n",
    "* `MAE` is much less biased\n",
    "* `MSPE` and `MAPE` are biased towards the small target\n",
    "  * because they assign high weights to the object with small target.\n",
    "* `RMSLE` is usually considered as better metric than `MAPE`\n",
    "  * since it is less biased towards small target yet works with relative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Discussed the metrics, sensitive to relative errors\n",
    "* **(R)MSPE**\n",
    "  - Weighted version of `MSE`\n",
    "\n",
    "* **MAPE**\n",
    "  - Weighted version of `MAE`\n",
    "\n",
    "* **(R)MSLE**\n",
    "  - `MSE` in logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
