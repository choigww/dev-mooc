{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Bound Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounds vs. Limitations\n",
    "\n",
    "In the last course, we covered the idea of memory limitations, and figured out some strategies to overcome them with Pandas. As a quick refresher, **a memory limitation is when a dataset won't fit into the memory available on your computer**. When this happens, you need to rely on workarounds, like \n",
    "* processing the data in batches that do fit into memory\n",
    "* relying on tools, like SQLite, that keep the data on disk instead of in memory while doing processing\n",
    "\n",
    "The important thing to note here is that **available memory is a hard limitation on what's possible to process**. If you have a 6 gigabyte dataset, and 4 gigabytes of memory, there's no way you can load your data into Pandas and process it without using a workaround.<br>\n",
    "\n",
    "In this course, we'll cover **the idea of program bounds**. A program bound is similar to a limitation in that it affects how you're able to process your data. **However, a program bound isn't a hard limitation -- if your program is bound, your computer will still be able to eventually process the data**. A program bound mostly limits `how quickly the program can be executed`. There are two primary ways a program can be bound that you'll need to be aware of:\n",
    "\n",
    "* **CPU-bound** -- A CPU-bound program will be dependent on your CPU to execute quickly. **The faster your processor is, the faster your program will be**.\n",
    "* **I/O-bound** -- An I/O-bound program will be dependent on external resources, like files on disk and network services to execute quickly. **The faster these external resources can be accessed, the faster your program will run**.\n",
    "\n",
    "As you work with larger datasets, understanding these bounds and how to make your program more efficient to deal with them is critical. **Relatively simple optimizations can mean the difference between processing a gigabyte of data in 30 minutes or in 30 seconds**.<br>\n",
    "\n",
    "Here's a diagram that shows how various components work together:\n",
    "\n",
    "![bounds-vs-limitations](https://s3.amazonaws.com/dq-content/168/CPU+and+I_O+bounds.png)\n",
    "\n",
    "As you can see above, **every time you load data from disk into memory, then process it, it travels through the I/O bridge twice, which takes time**. \n",
    "* The more efficient you make your code, \n",
    "* the less back and forth trips will need to be made, \n",
    "* and the faster your code will run. \n",
    "\n",
    "You can make your code more efficient by minimizing how many times you access data, or by ensuring that the processor has to run fewer instructions.<br>\n",
    "\n",
    "In this mission, we'll learn more about CPU-bound programs, and how we can understand and improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In this mission, we'll be working with a dataset of search terms and matching products from [CrowdFlower](https://www.crowdflower.com/data-for-everyone/). This dataset is an expanded version of the data used for a [Kaggle competition](https://www.kaggle.com/c/crowdflower-search-relevance). The full dataset contains `267373` rows, each of which represents a search for a product, with the search query used and the search result given. Each search result was scored for its relevance to the original query. There are quite a few columns in the dataset, but we're mainly interested in the `query` column. Here's a look at all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:variance</th>\n",
       "      <th>product_image</th>\n",
       "      <th>product_link</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_title</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>711158459</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs2.ebaystatic.com/d/l225/m/mzvzEUI...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$329.98</td>\n",
       "      <td>Sony PlayStation 4 (PS4) (Latest Model)- 500 G...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>1</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>711158460</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://thumbs3.ebaystatic.com/d/l225/m/mJNDmSy...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-Lat...</td>\n",
       "      <td>$324.84</td>\n",
       "      <td>Sony PlayStation 4 (Latest Model)- 500 GB Jet ...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>2</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>711158461</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://thumbs4.ebaystatic.com/d/l225/m/m10NZXA...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$324.83</td>\n",
       "      <td>Sony PlayStation 4 PS4 500 GB Jet Black Console</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>3</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>711158462</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs2.ebaystatic.com/d/l225/m/mZZXTmA...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-500...</td>\n",
       "      <td>$350.00</td>\n",
       "      <td>Sony - PlayStation 4 500GB The Last of Us Rema...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>4</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>711158463</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs3.ebaystatic.com/d/l225/m/mzvzEUI...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$308.00\\nTrending at\\n$319.99</td>\n",
       "      <td>Sony PlayStation 4 (PS4) (Latest Model)- 500 G...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>5</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   _unit_id  relevance  relevance:variance  \\\n",
       "0           0  711158459       3.67               0.471   \n",
       "1           1  711158460       4.00               0.000   \n",
       "2           2  711158461       4.00               0.000   \n",
       "3           3  711158462       3.67               0.471   \n",
       "4           4  711158463       3.33               0.471   \n",
       "\n",
       "                                       product_image  \\\n",
       "0  http://thumbs2.ebaystatic.com/d/l225/m/mzvzEUI...   \n",
       "1  http://thumbs3.ebaystatic.com/d/l225/m/mJNDmSy...   \n",
       "2  http://thumbs4.ebaystatic.com/d/l225/m/m10NZXA...   \n",
       "3  http://thumbs2.ebaystatic.com/d/l225/m/mZZXTmA...   \n",
       "4  http://thumbs3.ebaystatic.com/d/l225/m/mzvzEUI...   \n",
       "\n",
       "                                        product_link  \\\n",
       "0  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "1  http://www.ebay.com/itm/Sony-PlayStation-4-Lat...   \n",
       "2  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "3  http://www.ebay.com/itm/Sony-PlayStation-4-500...   \n",
       "4  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "\n",
       "                   product_price  \\\n",
       "0                       $329.98    \n",
       "1                       $324.84    \n",
       "2                       $324.83    \n",
       "3                       $350.00    \n",
       "4  $308.00\\nTrending at\\n$319.99   \n",
       "\n",
       "                                       product_title          query  rank  \\\n",
       "0  Sony PlayStation 4 (PS4) (Latest Model)- 500 G...  playstation 4     1   \n",
       "1  Sony PlayStation 4 (Latest Model)- 500 GB Jet ...  playstation 4     2   \n",
       "2    Sony PlayStation 4 PS4 500 GB Jet Black Console  playstation 4     3   \n",
       "3  Sony - PlayStation 4 500GB The Last of Us Rema...  playstation 4     4   \n",
       "4  Sony PlayStation 4 (PS4) (Latest Model)- 500 G...  playstation 4     5   \n",
       "\n",
       "  source                                                url  \n",
       "0   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "1   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "2   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "3   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "4   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ecommerce = pd.read_csv('../data/ecommerce5000.csv', encoding='latin-1')\n",
    "ecommerce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicate values\n",
    "\n",
    "In order to illustrate the idea of CPU bounds, let's start with a task that we've done numerous times before -- finding which values in a column are duplicates.<br>\n",
    "\n",
    "With Pandas, you can use methods like [pandas.DataFrame.duplicated](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html) to find duplicate values in columns. You can also find duplicate values using the [GROUP BY](https://www.sqlite.org/lang_select.html) statement in a SQL query. However, there are cases when you'll have to write your own function to find duplicate values:\n",
    "\n",
    "* You have complex custom logic around what constitutes a duplicate.\n",
    "* Your dataset doesn't fit into memory, and would take too long to batch process.\n",
    "* Your data is streaming, and you want to find duplicates in realtime.\n",
    "\n",
    "duplicate is to:\n",
    "* Create a list to store duplicate items.\n",
    "* Loop through each item in the `query` column.\n",
    "  * Loop through each item in the `query` column.\n",
    "    * If we're on the same item in the inner loop and outer loop, keep going.\n",
    "    * If a match is found, mark it as a duplicate row.\n",
    "  * Add the duplicate item to the duplicates list.\n",
    "\n",
    "The above algorithm will iterate through each value in the query column, and compare it to every other value in the query column. This will help us find duplicates. The algorithm will result in a nested for loop, like the below:\n",
    "\n",
    "```python\n",
    "# Initialize a list to store our duplicate \n",
    "duplicates = []\n",
    "​\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicate = False\n",
    "​\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        if i == z:\n",
    "            continue\n",
    "        # Mark as duplicate if we find a match.\n",
    "        if item == item2:\n",
    "            duplicate = True\n",
    "    # Add to the duplicates list.\n",
    "    if duplicate:\n",
    "        duplicates.append(item)\n",
    "```\n",
    "\n",
    "If we want to optimize our code later, we need to be able to figure out how long our code is taking to run. One easy way to do this is to count up the number of \"operations\" our code is performing. Let's say that an \"operation\" is any time we:\n",
    "* Assign a value to a variable\n",
    "* Modify a variable value\n",
    "* Check if two variables are equal\n",
    "\n",
    "Let's look through our code from above line by line, and see where the \"operations\" occur:\n",
    "\n",
    "* `duplicates = []` -- this assigns to a variable, so it is an operation.\n",
    "* `duplicate = False` -- this assigns to a variable, so it is an operation. Note that this occurs inside the for loop, so this operation could be called many times.\n",
    "* `if i == z` -- this checks if two variables are equal, so it's an operation. This occurs inside 2 for loops, so this operation will be called many times.\n",
    "* `if item == item2` -- this check if two variables are equal as well, so it's an operation.\n",
    "* `duplicate = True` -- this assigns to a variable, so it's an operation. This is inside two for loops, but also an if statement, so it may not be called that many times.\n",
    "* `if duplicate` -- this checks if duplicate == True, so it's an operation. It's only inside one for loop.\n",
    "* `duplicates.append(item)` -- this modifies a list, so it's an operation. This is only inside one for loop.\n",
    "\n",
    "We can count up how many times each of these operations occurs by incrementing a counter just before the operation occurs. Here's an example where we count up how many times the `i == z` operation is called:\n",
    "\n",
    "```python\n",
    "iz_operations = 0\n",
    "# Initialize a list to store our duplicates\n",
    "duplicates = []\n",
    "​\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicate = False\n",
    "​\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        iz_operations += 1\n",
    "        if i == z:\n",
    "            continue\n",
    "        # Mark as duplicate if we find a match.\n",
    "        if item == item2:\n",
    "            duplicate = True\n",
    "    # Add to the duplicates list.\n",
    "    if duplicate:\n",
    "        duplicates.append(item)\n",
    "```\n",
    "\n",
    "Let's count up and print how many times each operation is called, so we can see what parts of our code take the longest to run. We've read the `query` column into the `query` variable, which is a list, and only kept the first `5000` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the following operation counter variables:\n",
    "  * `iz_operations` -- Count how many times the `i == z` check is performed.\n",
    "  * `item_operations` -- Count how many times the `item == item2` check is performed.\n",
    "  * `duplicates_init` -- Count how many times the `duplicates = []` operation is performed.\n",
    "  * `duplicates_false` -- Count how many times the `duplicates = False` operation is performed.\n",
    "  * `duplicates_true` -- Count how many times the `duplicates = True` operation is performed.\n",
    "  * `if_duplicate` -- Count how many times the if `duplicate` operation is performed.\n",
    "  * `duplicates_append` -- Count how many times the `duplicates.append(duplicate)` operation is performed.\n",
    "* Perform the duplicate checking from above.\n",
    "  * Add in code to count up how many times each operation occurs.\n",
    "* View the operation counter variables in the variable inspector.\n",
    "* Do you see any interesting trends or patterns in the operation counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = list(ecommerce['query'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iz_operations = 0\n",
    "item_operations = 0\n",
    "duplicates_init = 0\n",
    "duplicates_false = 0\n",
    "duplicates_true = 0\n",
    "if_duplicate = 0\n",
    "duplicates_append = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store our duplicates\n",
    "duplicates_init += 1\n",
    "duplicates = []\n",
    "\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicates_false += 1\n",
    "    duplicate = False\n",
    "\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        iz_operations += 1\n",
    "        if i == z:\n",
    "            continue\n",
    "        \n",
    "        # Mark as duplicate if we find a match.\n",
    "        item_operations += 1\n",
    "        if item == item2:\n",
    "            duplicates_true +=1\n",
    "            duplicate = True\n",
    "    \n",
    "    # Add to the duplicates list.\n",
    "    if_duplicate += 1\n",
    "    if duplicate:\n",
    "        duplicates_append += 1\n",
    "        duplicates.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O notation\n",
    "\n",
    "As we mentioned earlier, our dataset has `5000` rows. This means that some operations happened once per row (in the \"outer\" for loop). Some operations, like checking if `i == z`, and `item == item2`, were run about `25000000` times, though. This is because the operations occurred inside the inner for loop. This means that they were run over every element in `query` `5000` times. Here's a diagram showing how the nested for loops run operations:\n",
    "\n",
    "![nested-operations](https://s3.amazonaws.com/dq-content/168/nested_operations.png)\n",
    "\n",
    "Each item in the \"outer\" for loop spawns an \"inner\" for loop, which executes as many times as `query` has elements. This means that the loop will run `len(query) * len(query)` times, or 5000 * 5000, which equals `25000000`. Let's say your code has a single operation that takes 1 second to run. If it runs `25000000` times, it would take `289` days to run, almost a whole year!<br>\n",
    "\n",
    "Compared to the \"cost\" in terms of time of nested for loops, the outer for loop and other operations take almost no time. The operations inside two for loops ran `49995000` times. All the other operations ran `179774` times, a negligible amount comparatively. Compared to the operations inside nested for loops, the other operations don't really matter from a performance perspective. If we wanted to improve our algorithm, removing the operation `duplicate = False` would save us too little time to be worth it. We'd have to optimize the operations that run `25000000` times each.<br>\n",
    "\n",
    "It also doesn't really matter that there are two operations that run `25000000` times instead of one. Each operation individually will take `289` days to run `25000000` times at `1` second per execution, so just removing one of the operations from our program won't really help us. We need to remove both to get our performance to a reasonable level.<br>\n",
    "\n",
    "Needing to measure how long algorithms such as this one take is very common in computer science, and it isn't practical to always count up the number of operation directly. This has led to the usage of [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation) to measure time complexity.<br>\n",
    "\n",
    "Big O notation is based on the same intuition that we just had -- that an algorithm's performance is limited by the operation that runs the most times. Big O notation expresses time complexity in terms of the length of the input variable, represented as `n`.<br>\n",
    "\n",
    "For example, here's a single for loop that runs across each element in a list once:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "for item in query:\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "The above algorithm would be represented in big O notation as having `O(n)` time complexity since we run the `counter += 1` operation `len(query)` times. Recall from above that `n` equals `len(query)` in our notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize a variable `total`, and set it to `0`.\n",
    "* Initialize the following operation counter variables:\n",
    "  * `sum_increments` -- count how many times `total` is incremented.\n",
    "* Write an algorithm that adds the length of each item in `query` to `total`.\n",
    "* Look at the value of `sum_increments`. Is it what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_increments = 0\n",
    "total = 0\n",
    "\n",
    "for item in query:\n",
    "    total += len(item)\n",
    "    sum_increments += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O(n^2)\n",
    "\n",
    "Here's an example with nested for loops:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "for item in query:\n",
    "    for item2 in query:\n",
    "        counter += 1\n",
    "```\n",
    "\n",
    "The above algorithm would be represented in big O notation as `O(n^2)`, since we're running the `counter += 1` operation `len(query) * len(query)` times. `len(query) * len(query)` equals `len(query) ^ 2`, and we're using `n` to represent `len(query)`, so that's where the `n^2` comes from.<br>\n",
    "\n",
    "Here's an example with three nested for loops:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "for item in query:\n",
    "    for item2 in query:\n",
    "        for item3 in query:\n",
    "            counter += 1\n",
    "```\n",
    "\n",
    "The above code will execute the `counter += 1` operation `len(query) * len(query) * len(query)` times, or `n^3`, meaning we represent the time complexity with `O(n^3)`.<br>\n",
    "\n",
    "In very rare cases, an algorithm will run in constant time, regardless of the length of the input variable. Here's an example:\n",
    "\n",
    "```python\n",
    "print(query[0])\n",
    "```\n",
    "\n",
    "The above code will always only execute a single operation, regardless of how long `query` is. This special case is represented as `O(1)` time, indicating that it's constant.<br>\n",
    "\n",
    "Big O notation is mostly concerned with the differences in magnitude. For example, going from `O(n^2)` to `O(n)` can usually create huge performance gains. Although the below code is technically `O(2n^2)`, it's common to just drop the 2 since the real performance gains would come from removing the inner for loop, not going from `2n^2` to `n^2`:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "for item in query:\n",
    "    for item2 in query:\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "```\n",
    "\n",
    "So we'd actually represent the above algorithm as having `O(n^2)` time complexity.<br>\n",
    "\n",
    "Now that we understand big O notation better, let's try to optimize our algorithm to have `O(n)` time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the following operation counter variables:\n",
    "  * `counts_increments` -- count how many times count is incremented.\n",
    "  * `value_checks` -- count how many times you check if a dictionary value is greater than 1.\n",
    "* Create a dictionary, `counts` to store item counts.\n",
    "* Loop over each item in query:\n",
    "  * If `item` isn't in `counts`, add it with the value set to `0`.\n",
    "  * Increment the value associated with `item` in `counts`.\n",
    "* Create a list, `duplicates` to store all the duplicates.\n",
    "* Loop over `counts`:\n",
    "  * If the value associated with any item is greater than 1, it's a duplicate, so append it to `duplicates`.\n",
    "* Print the operation counter variables.\n",
    "* Do you see any interesting trends or patterns in the operation counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_increments = 0\n",
    "value_checks = 0\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for item in query:\n",
    "    if item not in counts:\n",
    "        counts[item] = 0\n",
    "    counts[item] += 1\n",
    "    counts_increments += 1\n",
    "    \n",
    "duplicates = []\n",
    "\n",
    "for key, value in counts.items():\n",
    "    value_checks += 1\n",
    "    if value > 1:\n",
    "        duplicates.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing code runs\n",
    "\n",
    "**In the previous code screen, we managed to reduce the time complexity to `O(n)`.** It should also have been apparent from how long the code took to run that the algorithm ran much faster. \n",
    "* Note that **in order to lower time complexity, we had to increase the amount of data we stored in memory** (we had to store the `counts` dictionary). \n",
    "\n",
    "This is a common trade-off, and usually to increase performance in one aspect, you'll have to compromise in another aspect. It can be a delicate balance, and we'll cover it in more depth in future missions.<br>\n",
    "\n",
    "We also ignored quite a few operations inside the loops, such as the `if item not in counts` operation, and the `duplicates.append(key)` operation. This is due to what we said before about only changes in the exponent being major, and the number of operations inside a loop not being a huge factor.<br>\n",
    "\n",
    "Also note that although there are two for loops, we still assigned the complexity of `O(n)`. This is because in the worst case, where each value in `query` is unique, and counts has `5000` items, you're still separately looping over `query` twice. This leads to a time complexity of `O(n) + O(n)`, or `O(2n)`, which as we stated before, we simplify to `O(n)`. As you can see, the time complexity of a program depends on its slowest part, but we don't need to overanalyze and try to count every operation.<br>\n",
    "\n",
    "Big O notation is a great way for estimating the time complexity of algorithms where:\n",
    "\n",
    "* You can easily trace all of the function calls, and understand any nested time complexity.\n",
    "* The code is relatively straightforward.\n",
    "\n",
    "\n",
    "However, in many real-world cases, you'll be building complex code that doesn't make it easy to analyze on the level of individual operations. In these cases, instrumenting your code, and timing how long each piece takes, is a good way to understand performance. An easy way to instrument is to use the [time.time()](https://docs.python.org/3/library/time.html#time.time) function. The `time.time` function gives us the elapsed time in seconds since January 1st, 1970. This means subtracting one time from another gives you the number of seconds in between the times.<br>\n",
    "\n",
    "The below code will measure how many seconds `duplicates = []` takes to run:\n",
    "\n",
    "```python\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# We're timing how long this line takes to run.\n",
    "duplicates = []\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"Took {} seconds to run.\".format(elapsed))\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# We're timing how long this line takes to run.\n",
    "duplicates = []\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"Took {} seconds to run.\".format(elapsed))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find duplicate rows using Pandas.\n",
    "  * The variable `query_series` is a Pandas Series containing the values from the query column.\n",
    "  * Use the [pandas.Series.duplicated()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.duplicated.html) method to find duplicates.\n",
    "    * Assign the result to `duplicate_series`.\n",
    "  * Subset `query_series` using `duplicate_series` to get the actual values of the duplicates.\n",
    "  * Assign the values to `duplicate_values_series`.\n",
    "* Assign the total time elapsed finding duplicates in Pandas took to `pandas_elapsed`.\n",
    "* Print `pandas_elapsed`.\n",
    "* Find duplicate rows using the algorithm we used in the last screen.\n",
    "* Assign the total time elapsed finding duplicates with our algorithm to `elapsed`.\n",
    "* Print `elapsed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00307464599609375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "query_series = ecommerce['query']\n",
    "duplicated_series = query_series.duplicated()\n",
    "duplicate_values_series = query_series[duplicated_series]\n",
    "pandas_elapsed = time.time() - start\n",
    "print(pandas_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017020702362060547\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "counts = {}\n",
    "\n",
    "for item in query:\n",
    "    if item not in counts:\n",
    "        counts[item] = 0\n",
    "    counts[item] += 1\n",
    "\n",
    "duplicates = []\n",
    "\n",
    "for key, value in counts.items():\n",
    "    if value > 1:\n",
    "        duplicates.append(key)\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable time estimates\n",
    "\n",
    "Both algorithms ran pretty quickly -- around 1/50th of a second. You may notice that if you execute the code in the previous screen multiple times, the numbers will change by up to a factor of 2-3x each time. This is because the total runtime of the algorithms is low enough that small variances in things like what other programs are running, and memory latency can have a big effect on total runtime. **For example, if the system runs a cleanup process that takes 100% of the CPU every 15 minutes, if you get unlucky and run your script right as CPU usage is at 100%, you will see a very slow runtime**.<br>\n",
    "\n",
    "In order to get more stable results, you have to either:\n",
    "* Average out the random variation to get a more realistic look at runtime.\n",
    "* Run for long enough (over more data), so that the total runtime of your program is less susceptible to randomness.\n",
    "\n",
    "Two ways to accomplish this are to:\n",
    "* Use more data, so the total runtime is longer. This makes things less susceptible to random variation.\n",
    "* Run the same code multiple times, take the median of all the runs, and also plot a histogram.\n",
    "\n",
    "The first method isn't always practical, as there isn't always a way to execute an algorithm over more data. We'll try the second method to get more stable results. Having a histogram will also help us eyeball standard deviation, and see if there are any major outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert both of the algorithms from the last screen into functions.\n",
    "* Execute the pandas algorithm `1000` times. Find the median time it took to run, and assign to `median_pandas_runtime`.\n",
    "* Print `median_pandas_runtime`.\n",
    "* Create a histogram of the runtime the pandas algorithm using the [matplotlib.pyplot.hist()](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist) function.\n",
    "* Execute our algorithm `1000` times. Find the median time it took to run, and assign to `median_runtime`.\n",
    "* Print `median_runtime`.\n",
    "* Create a histogram of the runtime for our algorithm using the [matplotlib.pyplot.hist()](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_algorithm(times):\n",
    "    pandas_elapsed_list = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        \n",
    "        start = time.time()\n",
    "        duplicated_series = query_series.duplicated()\n",
    "        duplicate_values_series = query_series[duplicated_series]\n",
    "        pandas_elapsed = time.time() - start\n",
    "        \n",
    "        pandas_elapsed_list.append(pandas_elapsed)\n",
    "    \n",
    "    median_pandas_runtime = statistics.median(pandas_elapsed_list)\n",
    "    print(median_pandas_runtime)\n",
    "    plt.hist(median_pandas_runtime)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004119873046875\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRzcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109235c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_algorithm(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007491111755371094\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAXJiofLP/vsyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1092f0b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def our_algorithm(times):\n",
    "    elapsed_list = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        start = time.time()\n",
    "        counts = {}\n",
    "\n",
    "        for item in query:\n",
    "            if item not in counts:\n",
    "                counts[item] = 0\n",
    "            counts[item] += 1\n",
    "\n",
    "        duplicates = []\n",
    "\n",
    "        for key, value in counts.items():\n",
    "            if value > 1:\n",
    "                duplicates.append(key)\n",
    "        elapsed = time.time() - start\n",
    "        elapsed_list.append(elapsed)\n",
    "        \n",
    "    median_runtime = statistics.median(elapsed_list)\n",
    "    print(median_runtime)\n",
    "    plt.hist(elapsed_list)\n",
    "    plt.show()\n",
    "        \n",
    "our_algorithm(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring\n",
    "\n",
    "The performance differences in the previous screen may seem minor, but they really start to add up over time. Your specific time may be different, but let's say the Pandas algorithm took about `.0007` seconds, and our algorithm takes `.0008` seconds. The `.0001` difference doesn't matter with `5000` rows, but if we scale to `50000000` rows, it adds us to `5000` seconds. Not an enormous difference, but if you're running the code often, it can make a difference.<br>\n",
    "\n",
    "It's very rare to use the optimal algorithm the first time you implement something. It's worth using a combination of big O notation and timing to figure out where your bottlenecks are. Once you find a bottleneck, you can refactor it to find faster solutions.\n",
    "\n",
    "The general process behind refactoring is:\n",
    "* Measure how long the current code takes to run.\n",
    "* Rewrite the code so that the algorithm you want is nicely isolated from the rest of the code. Ideally, it will be a function, with defined inputs and outputs.\n",
    "* Try rewriting the algorithm to reduce time complexity.\n",
    "* Measure the new algorithm to see if it's faster.\n",
    "* Rinse and repeat as needed.\n",
    "\n",
    "**Refactoring is a critical skill, especially when old code that you wrote now has to deal with a much larger volume of data than you anticipated**.<br>\n",
    "\n",
    "Just as critical of a skill is to know when not to refactor. You generally want to identify the slowest part of your code and refactor it, versus making minor changes to faster-performing pieces. The key is to figure out where most of the runtime of your program is spent before you start refactoring. Going from our initial solution with two for loops to our second attempt made a huge difference, but switching from our second attempt to Pandas didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try writing your own version of the algorithm that we used to find unique values in `query`.\n",
    "* Measure the median elapsed time, and assign to `median_runtime`.\n",
    "* Print `median_runtime`.\n",
    "* Was your time better or worse than the times for the other approaches? Can you improve anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004680156707763672\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRj2klSAYS9JBRj2klSAYS9JBfwfONQoVKxr5IMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109316828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def my_algorithm(times):\n",
    "    elapsed_list = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        counts = {unq:0 for unq in set(query)}\n",
    "        duplicates = []\n",
    "        \n",
    "        for item in query:\n",
    "            \n",
    "            # eliminate unnecessary calculation.\n",
    "            if counts[item] > 1:\n",
    "                continue\n",
    "        \n",
    "            counts[item] += 1\n",
    "        \n",
    "        duplicates = [dup for dup, count in counts.items()\n",
    "                     if count > 1]\n",
    "        \n",
    "        elapsed = time.time() -start\n",
    "        elapsed_list.append(elapsed)\n",
    "        \n",
    "    median_runtime = statistics.median(elapsed_list)\n",
    "    print(median_runtime)\n",
    "    plt.hist(elapsed_list)\n",
    "    plt.show()\n",
    "        \n",
    "my_algorithm(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different approach:\n",
    "   * not execute a loop for all 'query' items\n",
    "   * instead execute a loop for only unique items in 'query'\n",
    "   \n",
    "### Result : Fastest among above (`0.000158`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00015735626220703125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQNAkjplAEhSpwwASeqUASBJnfo/R6kWwKgkcKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109446438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def my_algorithm_2(times):\n",
    "    elapsed_list = []\n",
    "    query_copy = query[:]\n",
    "    \n",
    "    for i in range(times):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        uniques = set(query)\n",
    "        \n",
    "        for unique in uniques:\n",
    "            try:\n",
    "                query_copy.remove(unique)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        duplicates = query_copy\n",
    "        \n",
    "        elapsed = time.time() -start\n",
    "        elapsed_list.append(elapsed)\n",
    "        \n",
    "    median_runtime = statistics.median(elapsed_list)\n",
    "    print(median_runtime)\n",
    "    plt.hist(elapsed_list)\n",
    "    plt.show()\n",
    "        \n",
    "my_algorithm_2(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate profiling strategies\n",
    "\n",
    "Constantly having to write lines to time different parts of your program is fine when you only want to profile a few lines, but it can be painful when you're trying to optimize a large program.<br>\n",
    "\n",
    "There are tools that can automatically profile your code, without you having to insert lines. Here are a few:\n",
    "* [cProfile](https://docs.python.org/3/library/profile.html) will show you how much time was spent in various levels of your application.\n",
    "* The unix [time](https://linux.die.net/man/1/time) command. Calling your program from the command line with syntax like `time python script.py` will show you how long your program took to run.\n",
    "* The [contexttimer](https://pypi.python.org/pypi/contexttimer/0.3.1) package will enable you to quickly time parts of your program without having to add lots of code.\n",
    "* The [lineprofiler](https://github.com/rkern/line_profiler) package will show you how long each line of a profiled function takes to execute.\n",
    "\n",
    "If you want to read about more profiling options, [here](https://docs.python.org/3/library/debug.html) is the Python documentation.<br>\n",
    "\n",
    "For now, let's use cProfile to profile our function from the last screen. You can use cProfile like this:\n",
    "\n",
    "```python\n",
    "import cProfile\n",
    "cProfile.run('print(10)')\n",
    "```\n",
    "\n",
    "Whatever code you pass into the [cProfile.run()](https://docs.python.org/3/library/profile.html#profile.run) will be executed. This code can execute functions or modules defined elsewhere in your code, so it's a good idea to use cProfile to run functions you've defined.<br>\n",
    "\n",
    "The output of the above cProfile run will look like this:\n",
    "\n",
    "```python\n",
    "38 function calls in 0.000 seconds\n",
    "​\n",
    "   Ordered by: standard name\n",
    "​\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
    "        3    0.000    0.000    0.000    0.000 iostream.py:180(schedule)\n",
    "        2    0.000    0.000    0.000    0.000 iostream.py:285(_is_master_process)\n",
    "        2    0.000    0.000    0.000    0.000 iostream.py:298(_schedule_flush)\n",
    "        2    0.000    0.000    0.000    0.000 iostream.py:361(write)\n",
    "        3    0.000    0.000    0.000    0.000 iostream.py:89(_event_pipe)\n",
    "        3    0.000    0.000    0.000    0.000 threading.py:1067(_wait_for_tstate_lock)\n",
    "        3    0.000    0.000    0.000    0.000 threading.py:1109(is_alive)\n",
    "        3    0.000    0.000    0.000    0.000 threading.py:501(is_set)\n",
    "        1    0.000    0.000    0.000    0.000 {built-in method exec}\n",
    "        2    0.000    0.000    0.000    0.000 {built-in method getpid}\n",
    "        2    0.000    0.000    0.000    0.000 {built-in method isinstance}\n",
    "        1    0.000    0.000    0.000    0.000 {built-in method print}\n",
    "        3    0.000    0.000    0.000    0.000 {built-in method urandom}\n",
    "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
    "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
    "        3    0.000    0.000    0.000    0.000 {method 'send' of 'zmq.backend.cython.socket.Socket' objects}\n",
    "</module></string>\n",
    "```\n",
    "\n",
    "As you can see, cProfile shows you not just how long your code took to run, but exactly what the time was spent on. Here's what each column means:\n",
    "* `ncalls` -- the number of calls made to this particular function.\n",
    "* `tottime` -- the total time spent on this call.\n",
    "* `percall` -- the total time spent per call.\n",
    "* `cumtime` -- the cumulative time spent across calls.\n",
    "* `percall` -- the cumulative time per call.\n",
    "\n",
    "As you can see, the print() function utilizes many other Python functions in the threading and iostream packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use cProfile to run the `algo` function.\n",
    "* Look at the output. Can you figure out what each line refers to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo():\n",
    "    unique = set()\n",
    "    duplicates = set()\n",
    "    for item in query:\n",
    "        if item in unique:\n",
    "            duplicates.add(item)\n",
    "        else:\n",
    "            unique.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5004 function calls in 0.002 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.002    0.002 <ipython-input-17-a7d97f52efa9>:1(algo)\n",
      "        1    0.000    0.000    0.002    0.002 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.002    0.002 {built-in method builtins.exec}\n",
      "     5000    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run('algo()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practicing writing efficient algorithms\n",
    "\n",
    "Now that you understand how to profile code and write efficient algorithms, let's see if we can code something that works across the whole dataset, which is `2673373` rows. We'll want to create an algorithm that:\n",
    "* Splits the data into groups based on `query`.\n",
    "* For each group:\n",
    "  * Finds the `product_link` with the highest `relevance`.\n",
    "\n",
    "Here's some information that may help you:\n",
    "* The data is already sorted by `query`, so looping across the data will work, as long as you handle term changes.\n",
    "* It may be faster to iterate over the data if you remove columns first.\n",
    "\n",
    "It's possible to complete this using [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html), but is it possible to build something faster on your own? \n",
    "### Try to aim for something that runs in `O(n)` time.\n",
    "\n",
    "The data has been read into the Dataframe `data`. Additionally, the `query` column is in the list `query`, the `relevance` column is in the list `relevance`, and the `product_link` column is in the list `product_link`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use pandas groupby to find the `product_link` with the highest `relevance` for each unique `query`.\n",
    "* Profile the pandas algorithm and see how long it takes to run. Assign the elapsed time to `pandas_elapsed`.\n",
    "  * If you're testing using your own timing, you don't want to run it more than `10` times to get a stable time estimate, as iterating over `2673373` rows will take a while.\n",
    "* Write your own code to perform the same operation.\n",
    "* See how long it takes to run. Assign the elapsed time to `elapsed`.\n",
    "  * If you're testing using your own timing, you don't want to run it more than `10` times to get a stable time estimate, as iterating over `2673373` rows will take a while.\n",
    "* Refactor and repeat until you're happy with your algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runtime(func, times):\n",
    "    elapsed = []\n",
    "    for i in range(times):\n",
    "        start = time.time()\n",
    "        func()\n",
    "        \n",
    "    elapsed.append(time.time() - start)\n",
    "    return statistics.median(elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_algo():\n",
    "    get_max_relevance = lambda x: x.loc[x[\"relevance\"].idxmax(), \"product_link\"]\n",
    "    return ecommerce.groupby(\"query\").apply(get_max_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def my_algo():\n",
    "    \n",
    "    ecommerce_cut = ecommerce[['query', 'relevance', 'product_link']]\n",
    "    query_unique = list(set(query))\n",
    "    groupby_data = []\n",
    "    \n",
    "    for qu in query_unique:\n",
    "        selected = ecommerce_cut[ecommerce_cut['query'] == qu]\n",
    "        groupby_data.append(selected.loc[selected['relevance'].idxmax])\n",
    "        \n",
    "    return pd.concat(groupby_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038282155990600586"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_runtime(pandas_algo, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32485008239746094"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_runtime(my_algo, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O Notation practice\n",
    "\n",
    "Now that we've practiced writing more efficient code, let's practice a bit with big O notation. Being able to identify the time complexity of code quickly is a very useful skill.<br>\n",
    "\n",
    "Let's also quickly introduce the concept of space complexity. Space complexity indicates how much additional space in memory our code uses over and above the input arguments.<br>\n",
    "\n",
    "#### For instance, this code has a space complexity of `O(1)` since it only uses constant storage:\n",
    "\n",
    "```python\n",
    "first = query[0]\n",
    "for item in query:\n",
    "    print(item)\n",
    "```\n",
    "\n",
    "We only store `first`, which is always just a single element, no matter how long the query list is.<br>\n",
    "\n",
    "This code has a space complexity of `O(n)`, since we're storing a new list that's equal to the original list in length:\n",
    "\n",
    "```python\n",
    "new_list = []\n",
    "for item in query:\n",
    "    new_list.append(item)\n",
    "```\n",
    "\n",
    "Note that the same rules about ignoring coefficients for `n` also applies here. The following code also has a space complexity of `O(n)`:\n",
    "\n",
    "```python\n",
    "new_list = []\n",
    "new_list2 = []\n",
    "for item in query:\n",
    "    new_list.append(item)\n",
    "    new_list2.append(item)\n",
    "```\n",
    "\n",
    "We can also have a space complexity of `O(n^2)`:\n",
    "\n",
    "```python\n",
    "new_list = []\n",
    "for item in query:\n",
    "    inner_list = []\n",
    "    for item in query:\n",
    "        inner_list.append(item)\n",
    "    new_list.append(inner_list)\n",
    "```\n",
    "\n",
    "Now that we have an overview of space complexity, let's see if we can figure out the time and space complexity of a few functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Figure out the time and space complexity of each of the functions shown.\n",
    "* Assign `0` to `algo1_space_complexity` if it's `O(1)`, `1` if it's `O(n)`, and so on.\n",
    "* Assign `0` to `algo1_time_complexity` if it's `O(1)`, `1` if it's `O(n)`, and so on.\n",
    "* Repeat for all of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo1_time_complexity = 1 # O(n)\n",
    "algo1_space_complexity = 0 # store a single element\n",
    "\n",
    "def algo1(data):\n",
    "    total = 0\n",
    "    for index, row in data.iterrows():\n",
    "        total += int(row[\"rank\"])\n",
    "    return total\n",
    "\n",
    "algo2_time_complexity = 1 # O(n)\n",
    "algo2_space_complexity = 1 # store multiple elements\n",
    "\n",
    "def algo2(data):\n",
    "    prices = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        price_search = re.search('.*(\\d+).*', row[\"product_price\"], re.IGNORECASE)\n",
    "\n",
    "        if price_search:\n",
    "            price = float(price_search.group(1))\n",
    "        else:\n",
    "            price = None\n",
    "        \n",
    "        prices.append(price)\n",
    "        \n",
    "    price_avg = statistics.mean([p for p in prices if p is not None])\n",
    "    weighted_relevance = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if prices[index] is not None:\n",
    "            price = prices[index] / price_avg\n",
    "        else:\n",
    "            price = price_avg\n",
    "        \n",
    "        weighted_relevance.append(float(row[\"relevance\"]) * price)\n",
    "    \n",
    "    return weighted_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You should now have a good idea of big O notation, profiling, and refactoring. These are critical and hard-to-develop skills, so make sure you practice them on your own, and ask for help in the Slack community if you need it. We'll be using these concepts extensively throughout the data engineering course.<br>\n",
    "\n",
    "If you want to do some further reading, here are some good resources:\n",
    "* [Time Complexity on Wikipedia](https://en.wikipedia.org/wiki/Time_complexity)\n",
    "* [Time Complexity in Python](https://wiki.python.org/moin/TimeComplexity)\n",
    "* [Complexity Analysis Introduction](http://discrete.gr/complexity/)\n",
    "* [Python 3 Profiling](https://docs.python.org/3/library/profile.html)\n",
    "\n",
    "Although we only covered profiling and refactoring as ways of improving the performance of CPU-bound programs here, there are other methods that we'll cover in subsequent missions. \n",
    "\n",
    "### Trying to improve the performance of CPU-bound and I/O-bound programs is a significant part of the work of a data engineer. \n",
    "\n",
    "In the next mission, we'll cover I/O-bound programs, and how to optimize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
