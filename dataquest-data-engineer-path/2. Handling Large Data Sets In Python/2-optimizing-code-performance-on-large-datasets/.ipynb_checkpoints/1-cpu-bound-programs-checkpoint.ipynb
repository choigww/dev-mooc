{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Bound Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounds vs. Limitations\n",
    "\n",
    "In the last course, we covered the idea of memory limitations, and figured out some strategies to overcome them with Pandas. As a quick refresher, **a memory limitation is when a dataset won't fit into the memory available on your computer**. When this happens, you need to rely on workarounds, like \n",
    "* processing the data in batches that do fit into memory\n",
    "* relying on tools, like SQLite, that keep the data on disk instead of in memory while doing processing\n",
    "\n",
    "The important thing to note here is that **available memory is a hard limitation on what's possible to process**. If you have a 6 gigabyte dataset, and 4 gigabytes of memory, there's no way you can load your data into Pandas and process it without using a workaround.<br>\n",
    "\n",
    "In this course, we'll cover **the idea of program bounds**. A program bound is similar to a limitation in that it affects how you're able to process your data. **However, a program bound isn't a hard limitation -- if your program is bound, your computer will still be able to eventually process the data**. A program bound mostly limits `how quickly the program can be executed`. There are two primary ways a program can be bound that you'll need to be aware of:\n",
    "\n",
    "* **CPU-bound** -- A CPU-bound program will be dependent on your CPU to execute quickly. **The faster your processor is, the faster your program will be**.\n",
    "* **I/O-bound** -- An I/O-bound program will be dependent on external resources, like files on disk and network services to execute quickly. **The faster these external resources can be accessed, the faster your program will run**.\n",
    "\n",
    "As you work with larger datasets, understanding these bounds and how to make your program more efficient to deal with them is critical. **Relatively simple optimizations can mean the difference between processing a gigabyte of data in 30 minutes or in 30 seconds**.<br>\n",
    "\n",
    "Here's a diagram that shows how various components work together:\n",
    "\n",
    "![bounds-vs-limitations](https://s3.amazonaws.com/dq-content/168/CPU+and+I_O+bounds.png)\n",
    "\n",
    "As you can see above, **every time you load data from disk into memory, then process it, it travels through the I/O bridge twice, which takes time**. \n",
    "* The more efficient you make your code, \n",
    "* the less back and forth trips will need to be made, \n",
    "* and the faster your code will run. \n",
    "\n",
    "You can make your code more efficient by minimizing how many times you access data, or by ensuring that the processor has to run fewer instructions.<br>\n",
    "\n",
    "In this mission, we'll learn more about CPU-bound programs, and how we can understand and improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In this mission, we'll be working with a dataset of search terms and matching products from [CrowdFlower](https://www.crowdflower.com/data-for-everyone/). This dataset is an expanded version of the data used for a [Kaggle competition](https://www.kaggle.com/c/crowdflower-search-relevance). The full dataset contains `267373` rows, each of which represents a search for a product, with the search query used and the search result given. Each search result was scored for its relevance to the original query. There are quite a few columns in the dataset, but we're mainly interested in the `query` column. Here's a look at all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:variance</th>\n",
       "      <th>product_image</th>\n",
       "      <th>product_link</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_title</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>711158459</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs2.ebaystatic.com/d/l225/m/mzvzEUI...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$329.98</td>\n",
       "      <td>Sony PlayStation 4 (PS4) (Latest Model)- 500 G...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>1</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>711158460</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://thumbs3.ebaystatic.com/d/l225/m/mJNDmSy...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-Lat...</td>\n",
       "      <td>$324.84</td>\n",
       "      <td>Sony PlayStation 4 (Latest Model)- 500 GB Jet ...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>2</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>711158461</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://thumbs4.ebaystatic.com/d/l225/m/m10NZXA...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$324.83</td>\n",
       "      <td>Sony PlayStation 4 PS4 500 GB Jet Black Console</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>3</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>711158462</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs2.ebaystatic.com/d/l225/m/mZZXTmA...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-500...</td>\n",
       "      <td>$350.00</td>\n",
       "      <td>Sony - PlayStation 4 500GB The Last of Us Rema...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>4</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>711158463</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.471</td>\n",
       "      <td>http://thumbs3.ebaystatic.com/d/l225/m/mzvzEUI...</td>\n",
       "      <td>http://www.ebay.com/itm/Sony-PlayStation-4-PS4...</td>\n",
       "      <td>$308.00\\nTrending at\\n$319.99</td>\n",
       "      <td>Sony PlayStation 4 (PS4) (Latest Model)- 500 G...</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>5</td>\n",
       "      <td>eBay</td>\n",
       "      <td>http://www.ebay.com/sch/i.html?_from=R40&amp;_trks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   _unit_id  relevance  relevance:variance  \\\n",
       "0           0  711158459       3.67               0.471   \n",
       "1           1  711158460       4.00               0.000   \n",
       "2           2  711158461       4.00               0.000   \n",
       "3           3  711158462       3.67               0.471   \n",
       "4           4  711158463       3.33               0.471   \n",
       "\n",
       "                                       product_image  \\\n",
       "0  http://thumbs2.ebaystatic.com/d/l225/m/mzvzEUI...   \n",
       "1  http://thumbs3.ebaystatic.com/d/l225/m/mJNDmSy...   \n",
       "2  http://thumbs4.ebaystatic.com/d/l225/m/m10NZXA...   \n",
       "3  http://thumbs2.ebaystatic.com/d/l225/m/mZZXTmA...   \n",
       "4  http://thumbs3.ebaystatic.com/d/l225/m/mzvzEUI...   \n",
       "\n",
       "                                        product_link  \\\n",
       "0  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "1  http://www.ebay.com/itm/Sony-PlayStation-4-Lat...   \n",
       "2  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "3  http://www.ebay.com/itm/Sony-PlayStation-4-500...   \n",
       "4  http://www.ebay.com/itm/Sony-PlayStation-4-PS4...   \n",
       "\n",
       "                   product_price  \\\n",
       "0                       $329.98    \n",
       "1                       $324.84    \n",
       "2                       $324.83    \n",
       "3                       $350.00    \n",
       "4  $308.00\\nTrending at\\n$319.99   \n",
       "\n",
       "                                       product_title          query  rank  \\\n",
       "0  Sony PlayStation 4 (PS4) (Latest Model)- 500 G...  playstation 4     1   \n",
       "1  Sony PlayStation 4 (Latest Model)- 500 GB Jet ...  playstation 4     2   \n",
       "2    Sony PlayStation 4 PS4 500 GB Jet Black Console  playstation 4     3   \n",
       "3  Sony - PlayStation 4 500GB The Last of Us Rema...  playstation 4     4   \n",
       "4  Sony PlayStation 4 (PS4) (Latest Model)- 500 G...  playstation 4     5   \n",
       "\n",
       "  source                                                url  \n",
       "0   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "1   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "2   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "3   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  \n",
       "4   eBay  http://www.ebay.com/sch/i.html?_from=R40&_trks...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ecommerce = pd.read_csv('../data/ecommerce5000.csv', encoding='latin-1')\n",
    "ecommerce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicate values\n",
    "\n",
    "In order to illustrate the idea of CPU bounds, let's start with a task that we've done numerous times before -- finding which values in a column are duplicates.<br>\n",
    "\n",
    "With Pandas, you can use methods like [pandas.DataFrame.duplicated](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html) to find duplicate values in columns. You can also find duplicate values using the [GROUP BY](https://www.sqlite.org/lang_select.html) statement in a SQL query. However, there are cases when you'll have to write your own function to find duplicate values:\n",
    "\n",
    "* You have complex custom logic around what constitutes a duplicate.\n",
    "* Your dataset doesn't fit into memory, and would take too long to batch process.\n",
    "* Your data is streaming, and you want to find duplicates in realtime.\n",
    "\n",
    "duplicate is to:\n",
    "* Create a list to store duplicate items.\n",
    "* Loop through each item in the `query` column.\n",
    "  * Loop through each item in the `query` column.\n",
    "    * If we're on the same item in the inner loop and outer loop, keep going.\n",
    "    * If a match is found, mark it as a duplicate row.\n",
    "  * Add the duplicate item to the duplicates list.\n",
    "\n",
    "The above algorithm will iterate through each value in the query column, and compare it to every other value in the query column. This will help us find duplicates. The algorithm will result in a nested for loop, like the below:\n",
    "\n",
    "```python\n",
    "# Initialize a list to store our duplicate \n",
    "duplicates = []\n",
    "​\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicate = False\n",
    "​\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        if i == z:\n",
    "            continue\n",
    "        # Mark as duplicate if we find a match.\n",
    "        if item == item2:\n",
    "            duplicate = True\n",
    "    # Add to the duplicates list.\n",
    "    if duplicate:\n",
    "        duplicates.append(item)\n",
    "```\n",
    "\n",
    "If we want to optimize our code later, we need to be able to figure out how long our code is taking to run. One easy way to do this is to count up the number of \"operations\" our code is performing. Let's say that an \"operation\" is any time we:\n",
    "* Assign a value to a variable\n",
    "* Modify a variable value\n",
    "* Check if two variables are equal\n",
    "\n",
    "Let's look through our code from above line by line, and see where the \"operations\" occur:\n",
    "\n",
    "* `duplicates = []` -- this assigns to a variable, so it is an operation.\n",
    "* `duplicate = False` -- this assigns to a variable, so it is an operation. Note that this occurs inside the for loop, so this operation could be called many times.\n",
    "* `if i == z` -- this checks if two variables are equal, so it's an operation. This occurs inside 2 for loops, so this operation will be called many times.\n",
    "* `if item == item2` -- this check if two variables are equal as well, so it's an operation.\n",
    "* `duplicate = True` -- this assigns to a variable, so it's an operation. This is inside two for loops, but also an if statement, so it may not be called that many times.\n",
    "* `if duplicate` -- this checks if duplicate == True, so it's an operation. It's only inside one for loop.\n",
    "* `duplicates.append(item)` -- this modifies a list, so it's an operation. This is only inside one for loop.\n",
    "\n",
    "We can count up how many times each of these operations occurs by incrementing a counter just before the operation occurs. Here's an example where we count up how many times the `i == z` operation is called:\n",
    "\n",
    "```python\n",
    "iz_operations = 0\n",
    "# Initialize a list to store our duplicates\n",
    "duplicates = []\n",
    "​\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicate = False\n",
    "​\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        iz_operations += 1\n",
    "        if i == z:\n",
    "            continue\n",
    "        # Mark as duplicate if we find a match.\n",
    "        if item == item2:\n",
    "            duplicate = True\n",
    "    # Add to the duplicates list.\n",
    "    if duplicate:\n",
    "        duplicates.append(item)\n",
    "```\n",
    "\n",
    "Let's count up and print how many times each operation is called, so we can see what parts of our code take the longest to run. We've read the `query` column into the `query` variable, which is a list, and only kept the first `5000` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the following operation counter variables:\n",
    "  * `iz_operations` -- Count how many times the `i == z` check is performed.\n",
    "  * `item_operations` -- Count how many times the `item == item2` check is performed.\n",
    "  * `duplicates_init` -- Count how many times the `duplicates = []` operation is performed.\n",
    "  * `duplicates_false` -- Count how many times the `duplicates = False` operation is performed.\n",
    "  * `duplicates_true` -- Count how many times the `duplicates = True` operation is performed.\n",
    "  * `if_duplicate` -- Count how many times the if `duplicate` operation is performed.\n",
    "  * `duplicates_append` -- Count how many times the `duplicates.append(duplicate)` operation is performed.\n",
    "* Perform the duplicate checking from above.\n",
    "  * Add in code to count up how many times each operation occurs.\n",
    "* View the operation counter variables in the variable inspector.\n",
    "* Do you see any interesting trends or patterns in the operation counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = list(ecommerce['query'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iz_operations = 0\n",
    "item_operations = 0\n",
    "duplicates_init = 0\n",
    "duplicates_false = 0\n",
    "duplicates_true = 0\n",
    "if_duplicate = 0\n",
    "duplicates_append = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store our duplicates\n",
    "duplicates_init += 1\n",
    "duplicates = []\n",
    "\n",
    "# Loop through each item in the query column.\n",
    "for i, item in enumerate(query):\n",
    "    duplicates_false += 1\n",
    "    duplicate = False\n",
    "\n",
    "    # Loop through each item in the query column.\n",
    "    for z, item2 in enumerate(query):\n",
    "        # If the outer and inner loops are on the same value, keep going.\n",
    "        # Without this, we'll falsely detect rows as duplicates.\n",
    "        iz_operations += 1\n",
    "        if i == z:\n",
    "            continue\n",
    "        \n",
    "        # Mark as duplicate if we find a match.\n",
    "        item_operations += 1\n",
    "        if item == item2:\n",
    "            duplicates_true +=1\n",
    "            duplicate = True\n",
    "    \n",
    "    # Add to the duplicates list.\n",
    "    if_duplicate += 1\n",
    "    if duplicate:\n",
    "        duplicates_append += 1\n",
    "        duplicates.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O notation\n",
    "\n",
    "As we mentioned earlier, our dataset has `5000` rows. This means that some operations happened once per row (in the \"outer\" for loop). Some operations, like checking if `i == z`, and `item == item2`, were run about `25000000` times, though. This is because the operations occurred inside the inner for loop. This means that they were run over every element in `query` `5000` times. Here's a diagram showing how the nested for loops run operations:\n",
    "\n",
    "![nested-operations](https://s3.amazonaws.com/dq-content/168/nested_operations.png)\n",
    "\n",
    "Each item in the \"outer\" for loop spawns an \"inner\" for loop, which executes as many times as `query` has elements. This means that the loop will run `len(query) * len(query)` times, or 5000 * 5000, which equals `25000000`. Let's say your code has a single operation that takes 1 second to run. If it runs `25000000` times, it would take `289` days to run, almost a whole year!<br>\n",
    "\n",
    "Compared to the \"cost\" in terms of time of nested for loops, the outer for loop and other operations take almost no time. The operations inside two for loops ran `49995000` times. All the other operations ran `179774` times, a negligible amount comparatively. Compared to the operations inside nested for loops, the other operations don't really matter from a performance perspective. If we wanted to improve our algorithm, removing the operation `duplicate = False` would save us too little time to be worth it. We'd have to optimize the operations that run `25000000` times each.<br>\n",
    "\n",
    "It also doesn't really matter that there are two operations that run `25000000` times instead of one. Each operation individually will take `289` days to run `25000000` times at `1` second per execution, so just removing one of the operations from our program won't really help us. We need to remove both to get our performance to a reasonable level.<br>\n",
    "\n",
    "Needing to measure how long algorithms such as this one take is very common in computer science, and it isn't practical to always count up the number of operation directly. This has led to the usage of [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation) to measure time complexity.<br>\n",
    "\n",
    "Big O notation is based on the same intuition that we just had -- that an algorithm's performance is limited by the operation that runs the most times. Big O notation expresses time complexity in terms of the length of the input variable, represented as `n`.<br>\n",
    "\n",
    "For example, here's a single for loop that runs across each element in a list once:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "for item in query:\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "The above algorithm would be represented in big O notation as having `O(n)` time complexity since we run the `counter += 1` operation `len(query)` times. Recall from above that `n` equals `len(query)` in our notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize a variable `total`, and set it to `0`.\n",
    "* Initialize the following operation counter variables:\n",
    "  * `sum_increments` -- count how many times `total` is incremented.\n",
    "* Write an algorithm that adds the length of each item in `query` to `total`.\n",
    "* Look at the value of `sum_increments`. Is it what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
