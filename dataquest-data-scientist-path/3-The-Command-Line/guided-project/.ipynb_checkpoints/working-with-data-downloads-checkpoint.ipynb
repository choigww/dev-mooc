{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: Working with Data Downloads\n",
    "\n",
    "Almost all of the data you work with as a data scientist will come from a remote source, such as another website on the Internet. **File downloads sometimes come in analysis-ready formats like CSV. At other times, the data will be in an archive format like TAR or ZIP. These formats compress files to reduce overall size, which makes them faster to download. Archive formats can also bundle multiple data files into a single archive file.**<br>\n",
    "\n",
    "In this guided project, we'll be working with an education data set in ZIP format. We'll learn how to extract the files inside the ZIP download and then work with them.<br>\n",
    "\n",
    "The data set we'll work with is called the **Civil Rights Data Collection.** It contains information on educational achievement and opportunities in the U.S., broken down by race and school. For example, it records the racial composition of the students enrolled in advanced classes at each school. Each row represents a school, while each column records an indicator of academic achievement.<br>\n",
    "\n",
    "For the purposes of this exercise, we'll be using a subset of the data that only contains 1 out of every 100 rows in the original data set. If you'd like to work with the original version, you can download it from [data.gov](https://catalog.data.gov/dataset/civil-rights-data-collection-2013-14)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can load and analyze the data, we'll need to extract the files that contain it from the archive file, `crdc201314csv.zip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "/home/dq/scripts$ ls\n",
    "/home/dq/scripts$ crdc201314csv.zip   read.py\n",
    "/home/dq/scripts$ unzip crdc201314csv.zip\n",
    "Archive:  crdc201314csv.zip\n",
    "  inflating: CRDC2013_14.csv\n",
    "  inflating: CRDC2013_14content.csv\n",
    "  inflating: CRDC_documentation_csv.txt\n",
    "  inflating: CRDC_usage_agreement.txt\n",
    "/home/dq/scripts$ rm crdc201314csv.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data set has more than `2000` columns, there's a separate file that explains what each column means. The explanatory file (or \"data dictionary\") is `CRDC2013_14content.csv`, while the data file itself is `CRDC2013_14.csv`.\n",
    "\n",
    "* We'll need to create a Python script, load `CRDC2013_14content.csv` using pandas, and then decide on a few columns to explore in greater depth.\n",
    "\n",
    "Recall that in order to run a script from the command line, we'll need to create a few lines of code and save them as a file. Let's say the following lines are already in a file called `read.py`:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Program executed successfully!\")\n",
    "```\n",
    "We could then run that script by typing `python read.py` on the command line.\n",
    "\n",
    "* We'll have to run our Python script using a `virtual environment` that has a pandas installation on it. The virtual environment we need to activate is in the `/dataquest/system/env/python3` folder. As you may recall from a previous mission, we'll need to run `source /dataquest/system/env/python3/bin/activate` to activate the virtual environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "/home/dq/scripts$ source /dataquest/system/env/python3/bin/activate\n",
    "(python3) /home/dq/scripts$ pip freeze\n",
    "(python3) /home/dq/scripts$ nano read.py\n",
    "```\n",
    "```nano\n",
    "import pandas\n",
    "contents = pd.read_csv('CRDC2013_14content.csv')\n",
    "print(contents.head())\n",
    "```\n",
    "\n",
    "```bash\n",
    "(python3) /home/dq/scripts$ python3 read.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at the column names more closely, here are some potentially interesting ones that popped out:\n",
    "\n",
    "* JJ - Indicates whether the school is part of a juvenile justice facility, or youth prison.\n",
    "* SCH_STATUS_MAGNET - Indicates whether the school is a magnet school, an advanced school for students who achieve high scores on certain tests.\n",
    "\n",
    "We can dig around for interesting patterns here by using `Series.value_counts()` to find unique values in each column. This will tell us how many schools are juvenile justice facilities or magnet schools.<br>\n",
    "\n",
    "We can also count how many students are in juvenile justice facilities by using the pandas.pivot_table() function to create a pivot table. Building a pivot table will allow us to aggregate `TOT_ENR_M` and `TOT_ENR_F` (which record school enrollment by gender) by `JJ` and `SCH_STATUS_MAGNET`. This will count up how many students are in magnet schools or juvenile justice facilities. <br>\n",
    "\n",
    "The Python code below, for example, will create a pivot table that counts the total number of male and female students in juvenile justice facilities:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "pd.pivot_table(data, values=[\"TOT_ENR_M\", \"TOT_ENR_F\"], index=\"JJ\", aggfunc=\"sum\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "(python3) /home/dq/scripts$ touch exploration.py\n",
    "(python3) /home/dq/scripts$ nano exploration.py\n",
    "```\n",
    "\n",
    "```nano\n",
    "import pandas as pd\n",
    "data = pd.read_scv('CRDC2013_14.csv', encoding=\"Latin-1\")\n",
    "print(data['JJ'].value_counts())\n",
    "print(data['SCH_STATUS_MAGNET'].value_counts())\n",
    "```\n",
    "\n",
    "```bash\n",
    "(python3) /home/dq/scripts$ python3 exploration.py\n",
    "...\n",
    "(python3) /home/dq/scripts$ nano exploration.py\n",
    "```\n",
    "\n",
    "```nano\n",
    "import pandas as pd\n",
    "data = pd.read_scv('CRDC2013_14.csv', encoding=\"Latin-1\")\n",
    "print(data['JJ'].value_counts())\n",
    "print(data['SCH_STATUS_MAGNET'].value_counts())\n",
    "print(pd.pivot_table(data, values=[\"TOT_ENR_M\", \"TOT_ENR_F\"], index=\"JJ\", aggfunc=\"sum\"))\n",
    "print(pd.pivot_table(data, values=[\"TOT_ENR_M\", \"TOT_ENR_F\"], index=\"SCH_STATUS_MAGNET\", aggfunc=\"sum\"))\n",
    "```\n",
    "\n",
    "```bash\n",
    "(python3) /home/dq/scripts$ python3 exploration.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the columns in our data break school attributes down by race and gender. The names of these columns begin with an abbreviation for the attribute name. `SCH_ENR` stands for \"school enrollment,\" for example. Next, they include a code name for race, such as `HP`. The last part is a code name for gender, which is either `F` or `M`. For example, the complete name for the column that records hispanic female enrollment is `SCH_ENR_HI_F`.<br>\n",
    "\n",
    "Here are the code names for each race:\n",
    "\n",
    "* HI - Hispanic\n",
    "* AM - American Indian\n",
    "* AS - Asian\n",
    "* HP - Hawaiian or Pacific Islander\n",
    "* BL - Black\n",
    "* WH - White\n",
    "* TR - Two or more races\n",
    "\n",
    "Here are the gender code names:\n",
    "\n",
    "* F - Female\n",
    "* M - Male\n",
    "\n",
    "The data set contains one column for every possible combination of racial and gender code names associated with an attribute -- that's why there are more than 2,000 columns!<br>\n",
    "\n",
    "Here's a list of all of the columns that indicate school enrollment, for example:\n",
    "\n",
    "* SCH_ENR_HI_M\n",
    "* SCH_ENR_HI_F\n",
    "* SCH_ENR_AM_M\n",
    "* SCH_ENR_AM_F\n",
    "* SCH_ENR_AS_M\n",
    "* SCH_ENR_AS_F\n",
    "* SCH_ENR_HP_M\n",
    "* SCH_ENR_HP_F\n",
    "* SCH_ENR_BL_M\n",
    "* SCH_ENR_BL_F\n",
    "* SCH_ENR_WH_M\n",
    "* SCH_ENR_WH_F\n",
    "* SCH_ENR_TR_M\n",
    "* SCH_ENR_TR_F\n",
    "\n",
    "There are also two columns that indicate total enrollment by gender:\n",
    "\n",
    "* TOT_ENR_M - Total male enrollment\n",
    "* TOT_ENR_F - Total female enrollment\n",
    "\n",
    "Several other column names combine race and gender codes, including:\n",
    "\n",
    "* SCH_HBREPORTED_DIS - Students who report being harrased or bullied\n",
    "* SCH_DISCWODIS_EXPWOE - Students without disabilities who were expelled from school\n",
    "* SCH_RET_G12 - Students who started and completed grade 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "(python3) /home/dq/scripts$ touch enrollment.py\n",
    "(python3) /home/dq/scripts$ nano enrollment.py\n",
    "```\n",
    "\n",
    "```nano\n",
    "import pandas as pd\n",
    "data = pd.read_scv('CRDC2013_14.csv', encoding=\"Latin-1\")\n",
    "data['total_enrollment'] = data.TOT_ENR_M + data.TOT_ENR_F\n",
    "\n",
    "all_enrollment = data.total_enrollment.sum()\n",
    "\n",
    "enrollment_colnames = ['SCH_ENR_HI_M','SCH_ENR_HI_F',' SCH_ENR_AM_M', 'SCH_ENR_AM_F', 'SCH_ENR_AS_M', 'SCH_ENR_AS_F', 'SCH_ENR_HP_M','SCH_ENR_HP_F','SCH_ENR_BL_M','SCH_ENR_BL_F','SCH_ENR_WH_M','SCH_ENR_WH_F','SCH_ENR_TR_M','SCH_ENR_TR_F']\n",
    "\n",
    "sub_enrollments = []\n",
    "for colname in enrollment_colnames:\n",
    "    print(colname, end=' : ')\n",
    "    print(data[colname].sum() / all_enrollment)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're working with data files, it's common to put them in a folder named data. This makes it easy to separate our scripts and findings from the source data. In cases where the source data is several hundred megabytes, it also makes it easier to share our code and findings only.\n",
    "\n",
    "* In order to do this, we'll need to create a folder, then move the data files into it. Finally, we'll need to rewrite our Python scripts so that they load the data files in that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "(python3) /home/dq/scripts$ mkdir data\n",
    "(python3) /home/dq/scripts$ mv CRDC_documentation_csv.txt data/\n",
    "(python3) /home/dq/scripts$ mv CRDC_usage_agreement.txt data/\n",
    "(python3) /home/dq/scripts$ mv CRDC_2013_14.csv data/\n",
    "(python3) /home/dq/scripts$ mv CRDC_2013_14content.csv data/\n",
    "```\n",
    "\n",
    "```bash\n",
    "(python3) /home/dq/scripts$ nano read.py\n",
    "data=pd.read_scv('data/CRDC2013_14.csv')\n",
    "\n",
    "(python3) /home/dq/scripts$ nano exploration.py\n",
    "data=pd.read_scv('data/CRDC2013_14.csv',encoding=\"Latin-1\")\n",
    "\n",
    "(python3) /home/dq/scripts$ nano enrollment.py\n",
    "data=pd.read_scv('data/CRDC2013_14.csv')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
