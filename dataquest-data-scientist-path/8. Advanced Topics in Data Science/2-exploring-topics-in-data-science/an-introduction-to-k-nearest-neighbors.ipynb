{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Data\n",
    "\n",
    "Before we get started with the K-Nearest Neighbors (kNN) algorithm, let's take a look at our data. Each row contains information on how a player performed during the 2013-2014 NBA season.<br>\n",
    "\n",
    "Here are a few of the columns:\n",
    "* `player` - The player's name\n",
    "* `pos` - The player's position\n",
    "* `g` - The number of games the player was in\n",
    "* `gs` - The number of games in which the player started\n",
    "* `pts` - The total points the player scored\n",
    "\n",
    "See [this site](http://www.databasebasketball.com/about/aboutstats.htm) for descriptions of the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['player' 'pos' 'age' 'bref_team_id' 'g' 'gs' 'mp' 'fg' 'fga' 'fg.' 'x3p'\n",
      " 'x3pa' 'x3p.' 'x2p' 'x2pa' 'x2p.' 'efg.' 'ft' 'fta' 'ft.' 'orb' 'drb'\n",
      " 'trb' 'ast' 'stl' 'blk' 'tov' 'pf' 'pts' 'season' 'season_end']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nba = pd.read_csv(\"data/nba_2013.csv\")\n",
    "\n",
    "# The names of the columns in the data\n",
    "print(nba.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the KNN Algorithm\n",
    "\n",
    "The kNN algorithm is based on the idea that we can predict values we don't know by matching them with the most similar values we do know.<br>\n",
    "\n",
    "Imagine that we have three different types of cars:\n",
    "\n",
    "```python\n",
    "car,horsepower,racing_stripes,is_fast\n",
    "Honda Accord,180,False,False\n",
    "Yugo,500,True,True\n",
    "Delorean DMC-12,200,True,True\n",
    "```\n",
    "\n",
    "Let's say that we now have another car:\n",
    "\n",
    "```python\n",
    "Chevrolet Camaro,400,True,Unknown\n",
    "```\n",
    "\n",
    "We don't know whether or not this car is fast, but we can make a prediction based on the most similar car whose speed we know. In this case, we would compare the `horsepower` and `racing_stripes` values to find the most similar car, which is the `Yugo`. Because the Yugo is fast, we would predict that the Camaro is also fast. This is an example of 1-nearest neighbors, because we only looked at the most similar car.<br>\n",
    "\n",
    "If we performed a 2-nearest neighbors, we would end up with two `True` values (for the Delorean and the Yugo), which would average out to `True`.<br>\n",
    "\n",
    "If we did 3-nearest neighbors, we would end up with two True values and a `False` value, which would average out to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Simliar Rows With Euclidean Distance\n",
    "\n",
    "Before we can make predictions with kNN, we need to find some way to figure out which data rows are \"closest\" to the row we're trying to predict.<br>\n",
    "\n",
    "A simple way to do this is to use Euclidean distance. The formula is:\n",
    "\n",
    "$$\n",
    "\\sqrt{(q_1-p_1)^2 + (q_2-p_2)^2 + \\cdots + (q_n-p_n)^2}\n",
    "$$\n",
    "\n",
    "Let's say we have these two rows (we've converted True/False to 1/0), and we want to find the distance between them:\n",
    "\n",
    "```python\n",
    "Honda Accord,180,0\n",
    "Chevrolet Camaro,400,1\n",
    "```\n",
    "\n",
    "We'd only select the numeric columns. The distance becomes $\\sqrt{(180-400)^2 + (0-1)^2}$, which is about equal to `220`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function for calculating the Euclidean distance between two pandas series objects.\n",
    "* Use the function to find the Euclidean distance between `selected_player` and each row in `nba`.\n",
    "  * Use the `.apply(func, axis=1)` method on dataframes to apply function `func` to each row.\n",
    "  * The function should take `row` as its first argument.\n",
    "  * Only use the columns in `distance_columns` to compute the distance. - See the [documentation on the apply() method](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.apply.html) if you get stuck.\n",
    "* Assign the resulting pandas series to `lebron_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(row):\n",
    "    inner_value = 0\n",
    "    \n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    \n",
    "    return math.sqrt(inner_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_player = nba[nba[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', \n",
    "                    'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', \n",
    "                    'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', \n",
    "                    'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lebron_distance = nba.apply(euclidean_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Columns\n",
    "\n",
    "You may have noticed that `horsepower` in the last example had a much larger impact on the final distance than `racing_stripes` did. That's because `horsepower` values are much larger in absolute terms, and therefore dwarf the impact of `racing_stripes` values in the Euclidean distance calculations.<br>\n",
    "\n",
    "This can be bad, because having larger values doesn't necessarily make a variable better at predicting which rows are similar.<br>\n",
    "\n",
    "A simple way to deal with this problem is to normalize all of the columns to have a mean of 0 and a standard deviation of 1. This ensures that no single column has a dominant impact on the Euclidean distance calculations.<br>\n",
    "\n",
    "To set a column's mean to 0, we have to find its current mean, then subtract it from every value in that column. To set the standard deviation to 1, we divide every value in the column by the current standard deviation. The formula is:\n",
    "\n",
    "$$x = \\frac{x-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize the columns in `nba_numeric`.\n",
    "  * Using `.mean()` on a dataframe will return the mean of each column.\n",
    "  * Using `.std()` will return the standard deviation of each column.\n",
    "* Assign the result to `nba_normalized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_numeric = nba[distance_columns]\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean())/nba_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg.</th>\n",
       "      <th>x3p</th>\n",
       "      <th>x3pa</th>\n",
       "      <th>x3p.</th>\n",
       "      <th>...</th>\n",
       "      <th>ft.</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.835906</td>\n",
       "      <td>0.384886</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.435088</td>\n",
       "      <td>-0.738401</td>\n",
       "      <td>-0.768505</td>\n",
       "      <td>0.319884</td>\n",
       "      <td>-0.700282</td>\n",
       "      <td>-0.716608</td>\n",
       "      <td>-0.117009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389712</td>\n",
       "      <td>0.260690</td>\n",
       "      <td>-0.129462</td>\n",
       "      <td>-0.013116</td>\n",
       "      <td>-0.645220</td>\n",
       "      <td>-0.468056</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>-0.667650</td>\n",
       "      <td>0.226515</td>\n",
       "      <td>-0.734621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.550487</td>\n",
       "      <td>1.095711</td>\n",
       "      <td>-0.187863</td>\n",
       "      <td>-0.045011</td>\n",
       "      <td>-0.581271</td>\n",
       "      <td>-0.649215</td>\n",
       "      <td>0.674593</td>\n",
       "      <td>-0.778936</td>\n",
       "      <td>-0.829601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.882950</td>\n",
       "      <td>1.387883</td>\n",
       "      <td>0.187020</td>\n",
       "      <td>0.565852</td>\n",
       "      <td>-0.530733</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>1.065446</td>\n",
       "      <td>-0.013760</td>\n",
       "      <td>1.363938</td>\n",
       "      <td>-0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116868</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>-0.457600</td>\n",
       "      <td>-0.308035</td>\n",
       "      <td>-0.290291</td>\n",
       "      <td>-0.405214</td>\n",
       "      <td>0.846880</td>\n",
       "      <td>-0.778936</td>\n",
       "      <td>-0.829601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520826</td>\n",
       "      <td>0.743773</td>\n",
       "      <td>0.283340</td>\n",
       "      <td>0.436083</td>\n",
       "      <td>-0.568895</td>\n",
       "      <td>-0.439307</td>\n",
       "      <td>0.385292</td>\n",
       "      <td>-0.524113</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>-0.328603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355062</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>1.599148</td>\n",
       "      <td>1.465144</td>\n",
       "      <td>1.577804</td>\n",
       "      <td>1.590172</td>\n",
       "      <td>0.228673</td>\n",
       "      <td>1.737992</td>\n",
       "      <td>1.430256</td>\n",
       "      <td>0.898007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578033</td>\n",
       "      <td>-0.383420</td>\n",
       "      <td>0.462221</td>\n",
       "      <td>0.216475</td>\n",
       "      <td>1.033919</td>\n",
       "      <td>-0.123066</td>\n",
       "      <td>-0.683520</td>\n",
       "      <td>1.182380</td>\n",
       "      <td>0.423107</td>\n",
       "      <td>1.729123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.359519</td>\n",
       "      <td>0.108454</td>\n",
       "      <td>0.149309</td>\n",
       "      <td>-0.319180</td>\n",
       "      <td>-0.331028</td>\n",
       "      <td>-0.475703</td>\n",
       "      <td>1.110379</td>\n",
       "      <td>-0.778936</td>\n",
       "      <td>-0.822068</td>\n",
       "      <td>-1.808704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709147</td>\n",
       "      <td>0.614951</td>\n",
       "      <td>0.138859</td>\n",
       "      <td>0.291341</td>\n",
       "      <td>-0.553630</td>\n",
       "      <td>-0.468056</td>\n",
       "      <td>0.709175</td>\n",
       "      <td>-0.141348</td>\n",
       "      <td>1.139262</td>\n",
       "      <td>-0.400878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         g        gs        mp        fg       fga       fg.  \\\n",
       "0 -0.835906  0.384886 -0.862207 -0.435088 -0.738401 -0.768505  0.319884   \n",
       "1 -1.550487  1.095711 -0.187863 -0.045011 -0.581271 -0.649215  0.674593   \n",
       "2  0.116868 -0.010016 -0.457600 -0.308035 -0.290291 -0.405214  0.846880   \n",
       "3  0.355062  0.779789  1.599148  1.465144  1.577804  1.590172  0.228673   \n",
       "4 -0.359519  0.108454  0.149309 -0.319180 -0.331028 -0.475703  1.110379   \n",
       "\n",
       "        x3p      x3pa      x3p.    ...          ft.       orb       drb  \\\n",
       "0 -0.700282 -0.716608 -0.117009    ...    -0.389712  0.260690 -0.129462   \n",
       "1 -0.778936 -0.829601       NaN    ...    -0.882950  1.387883  0.187020   \n",
       "2 -0.778936 -0.829601       NaN    ...    -0.520826  0.743773  0.283340   \n",
       "3  1.737992  1.430256  0.898007    ...     0.578033 -0.383420  0.462221   \n",
       "4 -0.778936 -0.822068 -1.808704    ...     0.709147  0.614951  0.138859   \n",
       "\n",
       "        trb       ast       stl       blk       tov        pf       pts  \n",
       "0 -0.013116 -0.645220 -0.468056  0.061410 -0.667650  0.226515 -0.734621  \n",
       "1  0.565852 -0.530733  0.020680  1.065446 -0.013760  1.363938 -0.534801  \n",
       "2  0.436083 -0.568895 -0.439307  0.385292 -0.524113  0.029924 -0.328603  \n",
       "3  0.216475  1.033919 -0.123066 -0.683520  1.182380  0.423107  1.729123  \n",
       "4  0.291341 -0.553630 -0.468056  0.709175 -0.141348  1.139262 -0.400878  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Nearest Neighbor\n",
    "\n",
    "Now we know enough to find the nearest neighbor of a given row. Instead of the Euclidean distance formula, we can use the `distance.euclidean` function from `scipy.spatial`, which is a much faster way to calculate Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the player who's most similar to LeBron James by our distance metric.\n",
    "  * You can accomplish this by finding the second lowest value in the `euclidean_distances` series (the lowest value will correspond to Lebron, as he is most similar to himself), and then cross-referencing the NBA dataframe with the same index.\n",
    "* Assign the name of the player to `most_similar_to_lebron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Fill in the NA values in nba_normalized\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Find the normalized vector for Lebron James\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Find the distance between Lebron James and everyone else.\n",
    "euclidean_distances = nba_normalized.apply(\\\n",
    "                        lambda row: distance.euclidean(row, lebron_normalized), \n",
    "                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carmelo Anthony'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_to_lebron_index = euclidean_distances.sort_values(ascending=True).index[1]\n",
    "\n",
    "most_similar_to_lebron = nba.iloc[most_similar_to_lebron_index]['player']\n",
    "most_similar_to_lebron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Training and Testing Tests\n",
    "\n",
    "Now that we know how to find the nearest neighbors, we can make predictions on a test set.<br>\n",
    "\n",
    "First, we have to generate testing and training sets. We'll use random sampling to do this. We'll randomly shuffle the index of the `nba` dataframe, and then pick rows using the randomly shuffled values.<br>\n",
    "\n",
    "If we didn't do this, we'd end up predicting and training on the same data set, which would overfit. We could do cross-validation also, which would be slightly better, but also slightly more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 31)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.dropna(how='any', axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = nba.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba\n",
    "random_indices = permutation(nba.index)\n",
    "\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba)/3)\n",
    "\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices\n",
    "test = nba.loc[random_indices[1:test_cutoff]]\n",
    "\n",
    "# Generate the train set with the rest of the data\n",
    "train = nba.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn\n",
    "\n",
    "Instead of having to do it all ourselves, we can use the [kNN implementation in scikit-learn](http://scikit-learn.org/stable/modules/neighbors.html). While scikit-learn (Sklearn for short) makes a regressor and a classifier available, we'll be using the regressor, as we have continuous values to predict on.<br>\n",
    "\n",
    "Sklearn performs the normalization and distance finding automatically, and lets us specify how many neighbors we want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns that we'll be using to make predictions\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# The column we want to predict\n",
    "y_column = [\"pts\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create the kNN model\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "\n",
    "# Make predictions on the test set using the fit model\n",
    "predictions = knn.predict(test[x_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Error\n",
    "\n",
    "Now that we know our predictions, we can compute the error involved as [mean squared error](http://en.wikipedia.org/wiki/Mean_squared_error). The formula is:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_{i}} - y_{i})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test[y_column]\n",
    "\n",
    "mse = mean_squared_error(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8801.5864661654141"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
