{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Model Selection\n",
    "\n",
    "In the previous mission, we worked to optimize our predictions by creating and selecting the features used to train our model. The other half of the optimization puzzle is to optimize the model itself— or more specifically, the algorithm used to train our model.<br>\n",
    "\n",
    "So far, we've been using the logistic regression algorithm to train our models, however there are hundreds of different machine learning algorithms from which we can choose. Each algorithm has different strengths and weaknesses, and so we need to select the algorithm that works best with our specific data— in this case our Kaggle competition.<br>\n",
    "\n",
    "The process of selecting the algorithm which gives the best predictions for your data is called model selection.<br>\n",
    "\n",
    "In this mission, we're going work with two new algorithms: k-nearest neighbors and random forests.<br>\n",
    "\n",
    "Before we begin, we'll need to import in the data. To save time, we have saved the features we created in the previous mission as CSV files, `train_modified.csv` and `holdout_modified.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_modified.csv')\n",
    "holdout = pd.read_csv('data/holdout_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Baseline Model\n",
    "\n",
    "We're going to train our models using all the columns in the train dataframe. This will cause a small amount of overfitting due to collinearity (as we discussed in the previous mission), but having more features will allow us to more thoroughly compare algorithms.\n",
    "\n",
    "So we have something to compare to, we're going to train a logistic regression model like in the previous two missions. We'll use cross validation to get a baseline score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a `linear_model.LogisticRegression` class.\n",
    "* Use the `model_selection.cross_val_score()` function to train and test a model assigning the result to `scores`, using:\n",
    "  * The LogisticRegression object you just created\n",
    "  * `all_X` and `all_y` as the the X and y parameters\n",
    "  * `10` folds\n",
    "* Calculate the mean of scores and assign the result to `accuracy_lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_X = train.drop(['Survived','PassengerId'],axis=1)\n",
    "all_y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(lr, all_X, all_y, cv=10)\n",
    "accuracy_lr = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823891442515\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model using K-Nearest Neighbors\n",
    "\n",
    "The logistic regression baseline model from the previous screen scored 82.4%.\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\n",
    "\n",
    "**The logistic regression algorithm works by calculating linear relationships between the features and the target variable** and using those to make predictions. Let's look at an algorithm that makes predictions using a different method.<br>\n",
    "\n",
    "The **k-nearest neighbors** algorithm finds the observations in our training set most similar to the observation in our test set, and uses the average outcome of those 'neighbor' observations to make a prediction. The 'k' is the number of neighbor observations used to make the prediction.<br>\n",
    "\n",
    "The plots below shows three simple k-nearest neighbors models where there are two features shown on each axis, and two outcomes, red and green.\n",
    "\n",
    "![https://s3.amazonaws.com/dq-content/187/knn_overview.svg](https://s3.amazonaws.com/dq-content/187/knn_overview.svg)\n",
    "\n",
    "* In the first plot, the value of k is 1, so the closest 1 neighbour to our gray dot is used, green, making the prediction **green**.\n",
    "* In the second plot, the value of k is 3, so the closest 3 neighbours to our gray dot are used, green, making the prediction **red** (2 red vs 1 green).\n",
    "* In the third plot, the value of k is 5, so the closest 5 neighbours to our gray dot are used, green, making the prediction **red** (3 red vs 2 green).\n",
    "\n",
    "If you'd like to learn more about the k-nearest neighbors algorithm, you might like to check out our free [Introduction to K-Nearest Neighbors](https://www.dataquest.io/m/139/introduction-to-k-nearest-neighbors/) mission.<br>\n",
    "\n",
    "Just like it does for logistic regression, scikit-learn has a class that makes it easy to use k-nearest neighbors to make predictions, `neighbors.KNeighborsClassifier`.<br>\n",
    "\n",
    "Scikit-learn's use of object-oriented design makes it easy to substitute one model for another. The syntax to instantiate a `KNeighborsClassifier` is very similar to the syntax we use for logistic regression.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "```\n",
    "\n",
    "The optional `n_neighbors` argument sets the value of `k` when predictions are made. The default value of `n_neighbors`is 5, but we're going to start by building a simple model that uses the closest neighbor to make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a `neighbors.KNeighborsClassifier` object, setting the `n_neighbors` argument to `1`.\n",
    "* Use the `model_selection.cross_val_score()` function to train and test a model assigning the result to scores, using:\n",
    "  * The `KNeighborsClassifier` object you just created.\n",
    "  * `all_X` and `all_y` as the the X and y parameters.\n",
    "  * `10` folds.\n",
    "* Calculate the mean of `scores` and assign the result to `accuracy_knn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78573828169333793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(kn, all_X, all_y, cv=10)\n",
    "\n",
    "accuracy_knn = scores.mean()\n",
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Different K Values\n",
    "\n",
    "The k-nearest neighbors model we trained in the previous screen had an accuracy score of 78.6%, worse than our baseline score of 82.4%.\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\n",
    "K-nearest neighbors, `k == 1`|78.6%\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides pure model selection, we can vary the settings of each model— for instance the value of k in our k-nearest neighbors model. This is called **hyperparameter optimization**.<br>\n",
    "\n",
    "We can use a loop and Python's inbuilt [`range()` class](https://docs.python.org/3/library/stdtypes.html#range) to iterate through different values for `k` and calculate the accuracy score for each different value. We will only want to test odd values for `k` to avoid ties, where both 'survived' and 'died' outcomes would have the same number of neighbors.<br>\n",
    "\n",
    "This is the syntax we would use to get odd values between 1-7 from `range()`:\n",
    "\n",
    "```python\n",
    ">>>  for k in range(1,8,2):\n",
    "...      print(k)\n",
    "     1\n",
    "     3\n",
    "     5\n",
    "     7\n",
    "```\n",
    "\n",
    "Note that we use the arguments `(1,8,2)` to get values between 1 and 7, since the created `range()` object contains numbers up to but not including the 8.<br>\n",
    "\n",
    "Let's use this technique to calculate the accuracy of our model for values of k from 1-49, storing the results in a dictionary.<br>\n",
    "\n",
    "To make the results easier to understand, we'll finish by plotting the scores. We have provided a helper function, `plot_dict()` which you can use to easily plot the dictionary.<br>\n",
    "\n",
    "Note that we expect this step to take a while to run, as we are training 250 models in total (*10 cross validation models for each of 25 values of k*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a for loop and the `range` class to iterate over odd values of `k` from 1-49, and in each iteration:\n",
    "  * Instantiate a `KNeighborsClassifier` object with the value of k for the `n_neighbors` argument.\n",
    "  * Use `cross_val_score` to create a list of scores using the newly created `KNeighborsClassifier` object, using `all_X`, `all_y`, and `cv=10` as the arguments.\n",
    "  * Calculate the mean of the list of `scores`.\n",
    "  * Add the mean of the `scores` to the dictionary `knn_scores`, using `k` for the key.\n",
    "* Use the `plot_dict()` helper function to plot the `knn_scores` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.78,0.83),rot=0)\n",
    "    plt.show()\n",
    "\n",
    "knn_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAFpCAYAAABDH1hhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKtwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11380f4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,50,2):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, all_X, all_y, cv=10)\n",
    "    knn_scores[i] = scores.mean()\n",
    "    \n",
    "    \n",
    "plot_dict(knn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Hyperparameter Optimization with Grid Search\n",
    "\n",
    "Looking at our plot from the previous screen we can see that a k value of 19 gave us our best score, and checking the `knn_scores` dictionary we can see that the score was `82.4%`, identical to our baseline (if we didn't round the numbers you would see that it's actually 0.01% less accurate).\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\t\n",
    "K-nearest neighbors, `k == 1`|78.6%|\t\n",
    "K-nearest neighbors, `k == 19`|82.4%|\t\n",
    "\n",
    "The technique we just used is called `grid search` - we train a number of models across a 'grid' of values and then searched for the model that gave us the highest accuracy.<br>\n",
    "\n",
    "Scikit-learn has a class to perform grid search, [`model_selection.GridSearchCV()`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). The `'CV'` in the name indicates that we're **performing both grid search and cross validation at the same time**.<br>\n",
    "\n",
    "By creating a dictionary of parameters and possible values and passing it to the `GridSearchCV` object you can automate the process. Here's what the code from the previous screen would look like, when implemented using the GridSearchCV class.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,50,2)\n",
    "}\n",
    "grid = GridSearchCV(knn, param_grid=hyperparameters, cv=10)\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "```\n",
    "\n",
    "Running this code will produce the following output:\n",
    "\n",
    "```\n",
    "{'n_neighbors': 19}\n",
    "0.82379349046\n",
    "```\n",
    "\n",
    "Our final step was to print the `GridSearchCV.best_params_` and `GridSearchCV.best_score_` attributes to retrieve the parameters of the best-performing model, and the score it achieved.<br>\n",
    "\n",
    "We can also use `GridSearchCV` to try combinations of different hyperparameters. Say we wanted to test values of `\"ball_tree\"`, `\"kd_tree\"`, and `\"brute\"` for the `algorithm` parameter and values of `1`, `3`, and `5` for the `n_neighbors` algorithm parameter. GridSearchCV would train and test 9 models (3 for the first hyperparameter times 3 for the second hyperparameter), shown in the diagram below.\n",
    "\n",
    "![https://s3.amazonaws.com/dq-content/187/gridsearch.svg](https://s3.amazonaws.com/dq-content/187/gridsearch.svg)\n",
    "\n",
    "Let's use `GridSearchCV` to turbo-charge our search for the best performing parameters for our model, by testing 40 combinations of three different hyperparameters.<br>\n",
    "\n",
    "We have chosen the specific hyperparameters by consulting the documentation for the `KNeighborsClassifier` class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a `KNeighborsClassifier` object.\n",
    "* Instantiate a `GridSearchCV` object, using:\n",
    "* The `KNeighborsClassifier` object you just created as the first (unnamed) argument\n",
    "  * The hyperparameters dictionary for the `param_grid`\n",
    "  * A `cv` of 10\n",
    "  * Fit the `GridSearchCV` object using `all_X` and `all_y`.\n",
    "* Assign the parameters of the best performing model to `best_params`\n",
    "* Assign the score of the of the best performing model to `best_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,20,2),\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"algorithm\": ['brute'],\n",
    "    \"p\": [1,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': range(1, 20, 2), 'weights': ['distance', 'uniform'], 'algorithm': ['brute'], 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "gridcv = GridSearchCV(knn, param_grid = hyperparameters, cv=10)\n",
    "gridcv.fit(all_X, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = gridcv.best_params_\n",
    "best_score = gridcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Random Forests\n",
    "\n",
    "You can download the submission file from the previous screen [here](https://s3.amazonaws.com/dq-content/187/submission_1.csv).<br>\n",
    "\n",
    "When you submit this toKaggle, you'll see it scores 75.6%, less than our best submission of 78.0%. While our model could be overfitting due to including all columns, it also seems like k-nearest neighbors may not be the best algorithm choice.\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\t\n",
    "K-nearest neighbors, `k == 1`|78.6%|\n",
    "K-nearest neighbors, `k == 19`|82.4%|\t\n",
    "K-nearest neighbors, best model from grid search|82.8%|75.6%\n",
    "\n",
    "Let's try another algorithm called **random forests**. **Random forests** is a specific type of **decision tree** algorithm. You have likely seen decision trees before as part of flow charts or infographics. Say we wanted to build a decision tree to help us [categorize an object as either being 'hotdog' or 'not hotdog'](https://www.youtube.com/watch?v=ACmydtFDTGs), we could construct a decision tree like the below:\n",
    "\n",
    "![https://s3.amazonaws.com/dq-content/187/decision_tree.svg](https://s3.amazonaws.com/dq-content/187/decision_tree.svg)\n",
    "\n",
    "Decision tree algorithms attempt to build the most efficient decision tree based on the training data, and then use that tree to make future predictions. If you'd like to learn about decision trees and random forests in detail, you should check out our [decision trees course](https://www.dataquest.io/course/decision-trees).<br>\n",
    "\n",
    "Scikit-learn contains a class for classification using the random forest algorithm, `ensemble.RandomForestClassifier`. Here's how to fit a model and make predictions using the `RandomForestClassifier` class:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf.fit(train_X,train_y)\n",
    "predictions = clf.predict(test_X)\n",
    "```\n",
    "\n",
    "Because the algorithm includes randomization, we have to set the `random_state` parameter to make sure our results are reproducible.<br>\n",
    "\n",
    "Let's use a `RandomForestClassifier` object with `cross_val_score()` as we did earlier to see how the algorithm performs with the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a `RandomForestClassifier` object, setting the `random_state` parameter to `1`.\n",
    "* Use the `cross_val_score()` function to generate a set of scores and assign the result to `scores`, using:\n",
    "  * The `RandomForestClassifer` object you just created as the estimator\n",
    "  * `all_X` and `all_y` for the train and test data\n",
    "  * A `cv` value of 10\n",
    "* Calculate the mean of scores and assign the result to `accuracy_rf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80701254114175458"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "scores = cross_val_score(rf, all_X, all_y, cv=10)\n",
    "\n",
    "accuracy_rf = scores.mean()\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning our Random Forests Model with GridSearch\n",
    "\n",
    "Using the default settings, our random forests model obtained a cross validation score of 80.7%.\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\t\n",
    "K-nearest neighbors, `k == 1`|78.6%|\n",
    "K-nearest neighbors, `k == 19`|82.4%|\t\n",
    "K-nearest neighbors, best model from grid search|82.8%|75.6%\n",
    "Random forests, default hyperparameters|80.7%|\n",
    "\n",
    "Just like we did with the k-nearest neighbors model, we can use `GridSearchCV` to test a variety of hyperparameters to find the best performing model.<br>\n",
    "\n",
    "The best way to see a list of available hyperparameters is by checking the documentation for the classifier— in this case, [the documentation for RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Let's use grid search to test out combinations of the following hyperparameters:\n",
    "\n",
    "* `criterion`: \"entropy\" or \"gini\"\n",
    "* `max_depth`: 5 or 10\n",
    "* `max_features`: \"log2\" or \"sqrt\"\n",
    "* `min_samples_leaf`: 1 or 5\n",
    "* `min_samples_split`: 3 or 5\n",
    "* `n_estimators`: 6 or 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a `RandomForestClassifer` object, setting the `random_state` parameter to `1`.\n",
    "* Instantiate a `GridSearchCV` object, using:\n",
    "  * The `RandomForestClassifer` object you just created as the first (unnamed) argument\n",
    "  * A dictionary of hyperparameters that matches the list above for the `param_grid` argument\n",
    "  * A `cv` of `10`.\n",
    "  * Fit the `GridSearchCV` object using `all_X` or `all_y`.\n",
    "* Assign the parameters of the best performing model to `best_params`\n",
    " Assign the score of the of the best performing model to `best_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"criterion\":(\"entropy\", \"gini\"),\n",
    "    \"max_depth\":(5,10),\n",
    "    \"max_features\":(\"log2\", \"sqrt\"),\n",
    "    \"min_samples_leaf\":(1, 5),\n",
    "    \"min_samples_split\":(3, 5),\n",
    "    \"n_estimators\":(6, 9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ('entropy', 'gini'), 'max_depth': (5, 10), 'max_features': ('log2', 'sqrt'), 'min_samples_leaf': (1, 5), 'min_samples_split': (3, 5), 'n_estimators': (6, 9)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "gridcv = GridSearchCV(rf, param_grid=hyperparams, cv=10)\n",
    "\n",
    "gridcv.fit(all_X, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = gridcv.best_params_\n",
    "best_score = gridcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'brute', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828282828283\n"
     ]
    }
   ],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Random Forset Predictions to Kaggle\n",
    "\n",
    "The cross-validation score for the best performing model was 82.9%, making it the best cross-validation score we've obtained in this mission.\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\t\n",
    "K-nearest neighbors, `k == 1`|78.6%|\n",
    "K-nearest neighbors, `k == 19`|82.4%|\t\n",
    "K-nearest neighbors, best model from grid search|82.8%|75.6%\n",
    "Random forests, default hyperparameters|80.7%|\n",
    "Random forests, best model from grid search|82.9%|\n",
    "\n",
    "Let's train it on the holdout data and create a submission file to see how it performs on the Kaggle leaderboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assign the best performing model from the `GridSearchCV object grid` to `best_rf`.\n",
    "* Make predictions on the data from `holdout_no_id` using the `best_rf model`, and assign the result to `holdout_predictions`.\n",
    "* Create a dataframe `submission` with two columns:\n",
    "  * `PassengerId`, with the values from the PassengerId column of the holdout dataframe.\n",
    "  * `Survived`, with the values from holdout_predictions.\n",
    "* Use the `DataFrame.to_csv` method to save the `submission` dataframe to the filename `submission_2.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_no_id = holdout.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = gridcv.best_estimator_\n",
    "holdout_predictions = best_rf.predict(holdout_no_id)\n",
    "\n",
    "submission_df = {\"PassengerId\": holdout['PassengerId'],\n",
    "                \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The submission file we created in the previous step is available for download [here](https://s3.amazonaws.com/dq-content/187/submission_2.csv).\n",
    "\n",
    "![https://s3.amazonaws.com/dq-content/187/submission_rank.png](https://s3.amazonaws.com/dq-content/187/submission_rank.png)\n",
    "\n",
    "If you submit this to Kaggle, it achieves a score of 77.1%, considerably better than our k-nearest neighbors score of 75.6% and very close (2 incorrect predictions) to our best score from the previous mission of 78.0%\n",
    "\n",
    "Model|Cross-validation score|Kaggle score\n",
    "---|---|---\n",
    "Previous best Kaggle score|82.3%|78.0%\n",
    "Logistic regression baseline|82.4%|\t\n",
    "K-nearest neighbors, `k == 1`|78.6%|\n",
    "K-nearest neighbors, `k == 19`|82.4%|\t\n",
    "K-nearest neighbors, best model from grid search|82.8%|75.6%\n",
    "Random forests, default hyperparameters|80.7%|\n",
    "Random forests, best model from grid search|82.9%|77.1%\n",
    "\n",
    "\n",
    "By combining our strategies for feature selection, feature engineering, model selection and model tuning, we'll be able to continue to improve our score.<br>\n",
    "\n",
    "The next and final mission in this course is a guided project, where we'll teach you how to combine everything you've learned into a real-life Kaggle workflow, and continue to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
