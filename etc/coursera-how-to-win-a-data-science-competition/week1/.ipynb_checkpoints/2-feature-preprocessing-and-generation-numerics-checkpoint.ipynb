{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature prerprocessing and generation with respect to models\n",
    "### - Numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "\n",
    "1. Numeric feature preprocessing is different for tree and non-tree models:\n",
    "  * Tree-based models don't depend on scaling\n",
    "  * Non-tree-based models hugely depend on scaling\n",
    "2. Most often used preprocessings:\n",
    "  * `MinMaxScaler` - `[0, 1]`\n",
    "  * `StandardScaler` - `mean=0, std=1`\n",
    "  * Rank - set spaces among sorted values to be equal\n",
    "  * `npl.log(1+x)` and `np.sqrt(1+x)`\n",
    "3. Feature generation is powered by:\n",
    "  * Prior knowledge\n",
    "  * Explanatory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models which depend on feature scale or not\n",
    "* kNN models get impact from scaling since it uses distance metric\n",
    "* **Linear models also have difficulties with differently scaled features** - regularization impact turns out to be proportional to feature scale.\n",
    "* Gradient descent methods can go crazy without a proper scaling.\n",
    "* Nueral nets also require feature scaling just like linear models.\n",
    "\n",
    "<br>\n",
    "\n",
    "![feature-pre-gen-1](img/feature-pre-gen-1.png)\n",
    "\n",
    "* Preprocessing\n",
    "  - Tree-based models\n",
    "    * Find the most useful split for each feature\n",
    "    * It won't change its behavior and its predictions\n",
    "    * It can multiply the feature by a constant and retrain the model\n",
    "  - Non-tree-based models (kNN, linear, neural nets)\n",
    "  \n",
    "* Feature generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: scaling\n",
    "\n",
    "`sklearn.preprocessing.MinMaxScaler`\n",
    "$$X = \\frac{(X - X.min())}{(X.max() - X.min())}$$\n",
    "\n",
    "`sklearn.preprocessing.StandardScaler`\n",
    "$$X = \\frac{(X - X.mean())}{X.std()}$$\n",
    "\n",
    "\n",
    "\n",
    "### We can optimize scaling parameter to boost features which seems to be more important for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: outliers\n",
    "\n",
    "* To protect linear models from the massive impacts of outliers, **we can clip feature values between two chosen values of lower and upper bound.**\n",
    "  * or by **percentiles** (e.g. zero to 99 percentiles)!\n",
    "  \n",
    "![](img/feature-pre-gen-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: rank\n",
    "\n",
    "Can be a better option than MinMaxScaler if we have outlies\n",
    "* because rank transformation will move the outlies closer to our objects.\n",
    "\n",
    "**example**\n",
    "- If we apply a rank to the source of array, it will change values to their indices. \n",
    "- If we apply a rank to the not-sorted array, it will sort the array; It applies mapping between values and indices in the source of array to the array.\n",
    "```\n",
    "rank([-100, 0, 1e5) == [0, 1, 2]\n",
    "rank([1000, 1, 10]) = [2, 0, 1]\n",
    "```\n",
    "\n",
    "### Linear models, kNN, nueral nets can benefit from this kind of transformation if we have no time to handle outliers manually.\n",
    "\n",
    "`scipy.stats.rankdata`\n",
    "* You need to store the creative mapping from features values to their rank values.\n",
    "* Alternatively, you can concatenate train and test data before applying rank transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: others\n",
    "Especially useful for neural nets - they drive too big values closer to the features' average value. Along with this, values near zero are more distinguishable. \n",
    "\n",
    "1. Log transform : `np.log(1 + x)`\n",
    "2. Raising to the power < 1: `np.sqrt(x + 2/3)`\n",
    "\n",
    "### Another important moment which holds `TRUE` for all prerpocessings:\n",
    "Sometimes it is beneficial \n",
    "* to **train a model on concatenated data frames produced by different preprocessings**\n",
    "* to **mix models training differently-preprocessed data**.\n",
    "\n",
    "KNN, linear models, neural nets can benefit hugely from this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "Ways to proceed:\n",
    "* prior knowledge\n",
    "* EDA\n",
    "\n",
    "![feature-gen-ex1](img/feature-gen-ex1.png)\n",
    "\n",
    "![feature-gen-ex2](img/feature-gen-ex2.png)\n",
    "\n",
    "### It is useful to now that adding, multiplcations, divisions and other features interactions can be of help not only for linear models.\n",
    "* Gradient Boost Decision Tree models are powerful, but it still experiences **difficulties with approximation of multiplications and divisions**.\n",
    "* Adding size feature explicitly can lead to a more robust model with less amount of trees.\n",
    "\n",
    "![feature-gen-ex3](img/feature-gen-ex3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
