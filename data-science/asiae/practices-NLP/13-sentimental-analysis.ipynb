{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "instrumental-moscow",
   "metadata": {},
   "source": [
    "# Sentimental Analysis\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 군산대학교 한국어 감성사전 사용\n",
    "https://github.com/park1200656/KnuSentiLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polar-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "path = './sentiment-dict/'\n",
    "\n",
    "with open(path+'pos_pol_word.txt', 'r') as f:\n",
    "    sentiment_dict['pos'] = f.read().split(\"\\n\")[19:]\n",
    "    \n",
    "with open(path+'neg_pol_word.txt', 'r') as f:\n",
    "    sentiment_dict['neg'] = f.read().split(\"\\n\")[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alert-smell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(-;', '(^^)', '(^-^)', '(^^*', '(^_^)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict['pos'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proud-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가난', '가난뱅이', '가난살이', '가난살이하다', '가난설음']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict['neg'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "prerequisite-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tokens):\n",
    "    pos, neg = 0, 0    \n",
    "    for token in tokens:\n",
    "        if token in sentiment_dict['pos']:\n",
    "            pos += 1\n",
    "        if token in sentiment_dict['neg']:\n",
    "            neg += 1\n",
    "    return [0, 1][pos>neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-stevens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-bottom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "downtown-motivation",
   "metadata": {},
   "source": [
    "## Naver News 감성분석 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vanilla-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "existing-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_naver_news(url):\n",
    "    #url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108'\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    news_with_tags = soup.select('div._article_body_contents')[0]\n",
    "    \n",
    "    sentences = []\n",
    "    for splist in sentence_split:\n",
    "        for sentence in splist:\n",
    "            if '. ' in sentence:\n",
    "                sentences += sentence.split('. ')\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                \n",
    "    sentences = [re.sub('<.+>', ' ', s) for s in sentences\n",
    "                if re.sub('<.+>', ' ', s) not in ['', ' ', '  ']]\n",
    "    \n",
    "    email_idx = 0\n",
    "    email_ptn = '[a-zA-Z0-9_\\-.]+@[a-z]+(?:\\.[a-z]+)+'\n",
    "    sentences_raw = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if '오류를 우회하기 위한' not in sentence:\n",
    "            if re.findall(email_ptn, sentence):\n",
    "                break\n",
    "            sentences_raw.append(sentence)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return sentences_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주호영 \"LH 특검 수용, 여야 국회의원 전수조사 제안\"',\n",
       " '민주당 \"주호영 요구 즉각 수용, 전수조사 바로 진행\"',\n",
       " '주호영 국민의힘 원내대표가 16일 긴급 기자회견을 열고 더불어민주당이 제안한 한국토지주택공사(LH) 사태 특검 수사 제안을 수용하겠다고 밝혔다',\n",
       " '앞서 국민의힘은 특검 출범까지 약 한 달이 소요되기 때문에 그동안 증거인멸이 우려된다며 특검 제안을 거부했다',\n",
       " '국민의힘은 일단 검찰이 수사에 착수한 후 특검이 출범하면 그동안의 수사내용을 이첩하자는 입장이었다.',\n",
       " '이날 주호영 원내대표는 국회 소통관에서 기자회견을 갖고 특검 뿐만 아니라 국회의원 전원과 직계존비속, 지방공적체는 물론 청와대 전수조사까지 역제안했다',\n",
       " '주호영 원내대표는 \"오늘 민주당의 한 의원이 3기 신도시 투기 의혹이 불거진 자신의 땅에 갑자기 감자를 심었다는 기사가 나왔다',\n",
       " '대통령부터 민주당 의원들까지 문재인 정권 인사 중 영농인을 자처하는 분들이 급증하면서 국민의 분노가 하늘을 찌른다\"며 \"국민의힘은 거두절미하고 국회의원 대상 강력한 전수조사는 물론 특검과 국정조사 실시를 요구한다\"고 했다',\n",
       " '이어 \"이번 3월 회기 중에 LH특검법안이 본회의에서 즉시 처리되도록 특검법 공동발의에 민주당은 즉각 협조하라',\n",
       " '특검이 실시될 때까지, 한두 달의 시간 동안 범죄자들이 증거인멸 여지를 갖지 못하도록 수사를 전담한 국수본은 조직의 명운을 걸고 강도 높은 수사를 벌여라',\n",
       " '검경수사권 조정의 공백 우려를 이번 LH투기 범죄 수사를 계기로 불식시키기 바란다\"고 요구했다.',\n",
       " ' 9일 경기남부경찰청 반부패경제범죄수사대가 신도시 투기 의혹과 관련해 압수수색중인 경기도 광명시 일직동 한국토지주택공사(LH) 광명시흥사업본부에 적막감이 감돌고 있다',\n",
       " '사진=뉴스1 ',\n",
       " '그는 \"국정조사요구서는 빠르면 오늘 중 제출하겠다',\n",
       " '항간에는 이번 3기 신도시 LH투기 파문과 관련해 공급의 명분과 개발이익의 극대화를 노리는 거대세력이 전국의 부동산값을 천정부지로 끌어올렸다는 의혹까지 국민들 사이에 번지고 있다\"며 \"국민의힘은 그래서 LH파문의 근원지인 ‘광명·시흥, 남양주왕숙, 인천계양테크노밸리, 하남교산, 고양창릉, 부천대장 공공주택지구’ 등 3기 신도시 토지거래자 전원에 대한 국정조사를 실시할 것을 요구한다\"고 했다',\n",
       " '그러면서 \"민주당에 재차 경고한다',\n",
       " '4월7일 선거일까지 어떻게든 시간 끌고 상황을 모면하려 잔꾀나 꼼수 부리지 말라\"면서 \"횡설수설 말잔치 벌이며 책임을 회피해봤자 국민은 다 알고 있다',\n",
       " '국민의힘 102명 전원처럼 민주당 의원 174명 전원의 동의를 빨리 확인해 검증대로 올라서라\"고 촉구했다.',\n",
       " '또 \"우리의 청와대 전수조사 요구를 고의로 누락하지 말라',\n",
       " '국회의원 전원과 직계존비속, 지방공적체는 물론 청와대 전수조사도 거듭 요구한다\"며 \"국민의 공정한 검증대에 당당하게 오르자\"고 주문했다',\n",
       " '민주당은 주호영 원내대표의 특검 요구를 즉각 수용하겠다고 밝히고 전수조사도 바로 착수하겠다고 밝혔다']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=100&oid=015&aid=0004513867'\n",
    "sentences = get_text_from_naver_news(url)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "enormous-payment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_sentiment(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "psychological-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([get_sentiment(s) for s in sentences]) / len([get_sentiment(s) for s in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-highland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broke-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\\n\\n주호영 \"LH 특검 수용, 여야 국회의원 전수조사 제안\"민주당 \"주호영 요구 즉각 수용, 전수조사 바로 진행\"국민의힘 주호영 원내대표. 사진=연합뉴스주호영 국민의힘 원내대표가 16일 긴급 기자회견을 열고 더불어민주당이 제안한 한국토지주택공사(LH) 사태 특검 수사 제안을 수용하겠다고 밝혔다.',\n",
       " '앞서 국민의힘은 특검 출범까지 약 한 달이 소요되기 때문에 그동안 증거인멸이 우려된다며 특검 제안을 거부했다.',\n",
       " '국민의힘은 일단 검찰이 수사에 착수한 후 특검이 출범하면 그동안의 수사내용을 이첩하자는 입장이었다.',\n",
       " '이날 주호영 원내대표는 국회 소통관에서 기자회견을 갖고 특검 뿐만 아니라 국회의원 전원과 직계존비속, 지방공적체는 물론 청와대 전수조사까지 역제안했다.',\n",
       " '주호영 원내대표는 \"오늘 민주당의 한 의원이 3기 신도시 투기 의혹이 불거진 자신의 땅에 갑자기 감자를 심었다는 기사가 나왔다. 대통령부터 민주당 의원들까지 문재인 정권 인사 중 영농인을 자처하는 분들이 급증하면서 국민의 분노가 하늘을 찌른다\"며 \"국민의힘은 거두절미하고 국회의원 대상 강력한 전수조사는 물론 특검과 국정조사 실시를 요구한다\"고 했다.',\n",
       " '이어 \"이번 3월 회기 중에 LH특검법안이 본회의에서 즉시 처리되도록 특검법 공동발의에 민주당은 즉각 협조하라. 특검이 실시될 때까지, 한두 달의 시간 동안 범죄자들이 증거인멸 여지를 갖지 못하도록 수사를 전담한 국수본은 조직의 명운을 걸고 강도 높은 수사를 벌여라. 검경수사권 조정의 공백 우려를 이번 LH투기 범죄 수사를 계기로 불식시키기 바란다\"고 요구했다.',\n",
       " '9일 경기남부경찰청 반부패경제범죄수사대가 신도시 투기 의혹과 관련해 압수수색중인 경기도 광명시 일직동 한국토지주택공사(LH) 광명시흥사업본부에 적막감이 감돌고 있다.',\n",
       " '사진=뉴스1그는 \"국정조사요구서는 빠르면 오늘 중 제출하겠다. 항간에는 이번 3기 신도시 LH투기 파문과 관련해 공급의 명분과 개발이익의 극대화를 노리는 거대세력이 전국의 부동산값을 천정부지로 끌어올렸다는 의혹까지 국민들 사이에 번지고 있다\"며 \"국민의힘은 그래서 LH파문의 근원지인 ‘광명·시흥, 남양주왕숙, 인천계양테크노밸리, 하남교산, 고양창릉, 부천대장 공공주택지구’ 등 3기 신도시 토지거래자 전원에 대한 국정조사를 실시할 것을 요구한다\"고 했다.',\n",
       " '그러면서 \"민주당에 재차 경고한다. 4월7일 선거일까지 어떻게든 시간 끌고 상황을 모면하려 잔꾀나 꼼수 부리지 말라\"면서 \"횡설수설 말잔치 벌이며 책임을 회피해봤자 국민은 다 알고 있다. 국민의힘 102명 전원처럼 민주당 의원 174명 전원의 동의를 빨리 확인해 검증대로 올라서라\"고 촉구했다.',\n",
       " '또 \"우리의 청와대 전수조사 요구를 고의로 누락하지 말라. 국회의원 전원과 직계존비속, 지방공적체는 물론 청와대 전수조사도 거듭 요구한다\"며 \"국민의 공정한 검증대에 당당하게 오르자\"고 주문했다.',\n",
       " '민주당은 주호영 원내대표의 특검 요구를 즉각 수용하겠다고 밝히고 전수조사도 바로 착수하겠다고 밝혔다.',\n",
       " '김명일 한경닷컴 기자 mi737@hankyung.com▶ 경제지 네이버 구독 첫 400만, 한국경제 받아보세요▶ 한경 고품격 뉴스레터, 원클릭으로 구독하세요▶ 한국경제신문과 WSJ, 모바일한경으로 보세요',\n",
       " 'ⓒ 한국경제 & hankyung.com, 무단전재 및 재배포 금지']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "news_with_tags = soup.select('div._article_body_contents')[0]\n",
    "kss.split_sentences(news_with_tags.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "wrong-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_sentiment(k) for k in kss.split_sentences(news_with_tags.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-consultation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opposite-eclipse",
   "metadata": {},
   "source": [
    "## Naive Bayes 감정 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "residential-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(\"I love you\", 1),\n",
    "        (\"love you happy weekend\", 1),\n",
    "        (\"bore work job\", 0),\n",
    "        (\"I hate you\", 0),\n",
    "        (\"bore weekend\", 0),\n",
    "        (\"happy together\", 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "typical-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "    \n",
    "def detect_spam_NB(training_set, email_words, unseen_word_accept=True):\n",
    "    \n",
    "    doc_cnt0 = 0 \n",
    "    doc_cnt1 = 0 \n",
    "\n",
    "    wordfreq = defaultdict(lambda : [0, 0])\n",
    "\n",
    "    for doc, label in training_set:\n",
    "        words = doc.split()\n",
    "        for word in words:\n",
    "            wordfreq[word][label] += 1\n",
    "    \n",
    "    # word check\n",
    "    for word in email_words:\n",
    "        if word not in wordfreq.keys():\n",
    "            if not unseen_word_accept:\n",
    "                assert word not in email_words, \"Invalid word list.\" # assert\n",
    "            wordfreq[word] = [1, 1] # set 50% / 50%\n",
    "                \n",
    "    \n",
    "    for key, (cnt0, cnt1) in wordfreq.items():\n",
    "        doc_cnt0 += cnt0 # normal count\n",
    "        doc_cnt1 += cnt1 # spam count\n",
    "    \n",
    "    cond_prob_dict = wordfreq.copy()\n",
    "    k = 0.5\n",
    "    prob_norm = (doc_cnt0) / (doc_cnt0 + doc_cnt1)\n",
    "    prob_spam = 1 - prob_norm\n",
    "    \n",
    "    # Laplace Smoothing 적용\n",
    "    for key, (cnt0, cnt1) in wordfreq.items():\n",
    "        # 스팸메일일 때 해당 단어가 출현할 확률\n",
    "        prob_word_given_1 = (k + cnt1) / (2 * k + doc_cnt1)\n",
    "\n",
    "        # 일반메일일 때 해당 단어가 출현할 확률\n",
    "        prob_word_given_0 = (k + cnt0) / (2 * k + doc_cnt0)\n",
    "        \n",
    "        # cond_prob_dict 업데이트\n",
    "        cond_prob_dict[key] = [prob_word_given_0, prob_word_given_1]\n",
    "    \n",
    "    # ㅣog 변환 - 언더플로우 방지\n",
    "    log_cond_prob_dict = {key:[np.log(v0), np.log(v1)] for (key,[v0, v1]) in cond_prob_dict.items()}\n",
    "    \n",
    "    #print(log_cond_prob_dict)\n",
    "    \n",
    "    # 계산\n",
    "    numerators_0_given_words = np.exp(np.sum([log_cond_prob_dict[word][0] for word in email_words]))\n",
    "    numerators_1_given_words = np.exp(np.sum([log_cond_prob_dict[word][1] for word in email_words]))\n",
    "    denominator = numerators_0_given_words + numerators_1_given_words\n",
    "    \n",
    "    #print(numerators_spam_given_words, denominator)\n",
    "    \n",
    "    prob_0_given_words = numerators_0_given_words / denominator\n",
    "    prob_1_given_words = 1 - prob_0_given_words\n",
    "    \n",
    "    return round(prob_1_given_words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "certified-module",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(train, [\"love\", \"weekend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-economics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-shipping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "macro-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), # DTM - Document-Term Matrix\n",
    "                     ('tfidf', TfidfTransformer()), # tf-idf 계산\n",
    "                     ('clf', MultinomialNB())]) # tf-idf 수치 기반으로 NB classification\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,\n",
    "                        twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "\n",
    "# accuracy\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range' : [(1, 1), (1, 2)], # (1,1) = unigram, (1,2) = bigram\n",
    "              'tfidf__use_idf' : (True, False),\n",
    "              'clf__alpha' : (0.001, 0.01, 0.1, 0.5, 1.0)\n",
    "             }\n",
    "\n",
    "gscv_clf = GridSearchCV(text_clf, parameters,\n",
    "                       n_jobs=-1, verbose=3)\n",
    "gscv_clf_fit = gscv_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gscv_clf.best_estimator_.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-static",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-headquarters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rolled-combining",
   "metadata": {},
   "source": [
    "# ratings.txt 분석\n",
    "using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "revolutionary-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "oriental-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'ratings.txt', sep='\\t').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "latest-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cardiac-leader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199992, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "careful-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['document'],\n",
    "                                                   df['label'],\n",
    "                                                   random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "noted-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), # DTM - Document-Term Matrix\n",
    "                     ('tfidf', TfidfTransformer()), # tf-idf 계산\n",
    "                     ('clf', MultinomialNB())]) # tf-idf 수치 기반으로 NB classification\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bizarre-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332533301332053"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-divide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "geographic-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range' : [(1, 1), (1, 2)], # (1,1) = unigram, (1,2) = bigram\n",
    "              'tfidf__use_idf' : (True, False),\n",
    "              'clf__alpha' : (0.001, 0.01, 0.1, 0.5, 1.0)\n",
    "             }\n",
    "\n",
    "gscv_clf = GridSearchCV(text_clf, parameters,\n",
    "                       n_jobs=-1, verbose=3)\n",
    "gscv_clf_fit = gscv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "collaborative-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370534821392855"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_clf_pred = gscv_clf_fit.best_estimator_.predict(X_test)\n",
    "np.mean(gscv_clf_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "documented-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>predict</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92366</th>\n",
       "      <td>왜 요즘에는 이런영화가 나오지 않는 것인가! 광해? 7번방의선물? 신세계? 개나줘버려!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172729</th>\n",
       "      <td>샴푸의 Trouble만 좋았음</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>완전 짱!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158066</th>\n",
       "      <td>진정성이 느껴지지 않는, 그저그런 영화.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>권상우씨 풋풋했을때 정말 멋있으셨네^^ 그리고종혁아빠는 보다가 종혁아빠아닌줄 ㄷㄷ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193820</th>\n",
       "      <td>제목을 액션임파서블 아니면 무술임파서블 이라 하면 좋을 듯~! 완벽한 톰형 최대의....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136388</th>\n",
       "      <td>지루하다. 어색한 사투리</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120008</th>\n",
       "      <td>너무 황당해서 로그인하게 만드는 영화네. 설마 죽을줄은 ㅡㅡ??</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75562</th>\n",
       "      <td>포켓몬 받으려구....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30363</th>\n",
       "      <td>좀비영화 새벽의저주로 입문하면 다른거 볼게없다 ㅋㅋ 이게 최고거든</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  predict  real\n",
       "92366    왜 요즘에는 이런영화가 나오지 않는 것인가! 광해? 7번방의선물? 신세계? 개나줘버려!        1     1\n",
       "172729                                   샴푸의 Trouble만 좋았음        1     0\n",
       "495                                               완전 짱!!!        1     1\n",
       "158066                             진정성이 느껴지지 않는, 그저그런 영화.        0     0\n",
       "8246    권상우씨 풋풋했을때 정말 멋있으셨네^^ 그리고종혁아빠는 보다가 종혁아빠아닌줄 ㄷㄷ ...        1     1\n",
       "...                                                   ...      ...   ...\n",
       "193820  제목을 액션임파서블 아니면 무술임파서블 이라 하면 좋을 듯~! 완벽한 톰형 최대의....        0     0\n",
       "136388                                      지루하다. 어색한 사투리        0     0\n",
       "120008                너무 황당해서 로그인하게 만드는 영화네. 설마 죽을줄은 ㅡㅡ??        0     0\n",
       "75562                                        포켓몬 받으려구....        0     1\n",
       "30363                좀비영화 새벽의저주로 입문하면 다른거 볼게없다 ㅋㅋ 이게 최고거든        0     1\n",
       "\n",
       "[49998 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'review' : X_test,\n",
    "              'predict' : gscv_clf_pred,\n",
    "              'real' : y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-microwave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-private",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
