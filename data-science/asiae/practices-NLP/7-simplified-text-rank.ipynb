{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-beads",
   "metadata": {},
   "source": [
    "# Simplified TextRank\n",
    "- using class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "satisfactory-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "based-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(tokens, window=2):\n",
    "    \n",
    "    nodes = list(set(tokens))\n",
    "    vocab = nodes\n",
    "    vocab2idx = {k:i for (i,k) in enumerate(nodes)}\n",
    "    idx2vocab = {i:k for (i,k) in enumerate(nodes)}\n",
    "    \n",
    "    idx = list(idx2vocab.keys())\n",
    "    #print(idx)\n",
    "    \n",
    "    res_dict = {k:[] for k in vocab}\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        #print(token)\n",
    "        leng = len(tokens)\n",
    "        \n",
    "        min_idx = max(0, i-window+1)\n",
    "        max_idx = min(leng, i+window)\n",
    "        \n",
    "        for t in tokens[min_idx:max_idx]:  \n",
    "            if t != token:\n",
    "                res_dict[token].append(t)\n",
    "    \n",
    "    #print('with duplicates', res_dict)\n",
    "    res_dict = {k:list(set(v)) for k, v in res_dict.items()}\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sought-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trNode:\n",
    "    def __init__(self, name, damping_factor=0.85):\n",
    "        self.name = name\n",
    "        self.d = damping_factor\n",
    "        self.fnodes = []\n",
    "        \n",
    "        # initial score\n",
    "        self.score = 1\n",
    "        \n",
    "    def update_score(self):\n",
    "        # update node score\n",
    "        input_weights = [fnode.score/len(fnode.fnodes) for fnode in self.fnodes]\n",
    "        self.score = (1-self.d) + self.d * sum(input_weights)\n",
    "        \n",
    "    def update_fnodes(self, nodes):\n",
    "        for node in nodes:\n",
    "            self.fnodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "excited-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textRank:\n",
    "    def __init__(self, nodes):\n",
    "        self.nodes = nodes\n",
    "        \n",
    "    def update_nodes(self, times=None, threshold = 0.0001):\n",
    "        # limited times\n",
    "        if times:\n",
    "            for i in range(times):\n",
    "                [n.update_score() for n in self.nodes]\n",
    "                return [(n.name, n.score) for n in self.nodes]\n",
    "        # until convergence (< threshold)\n",
    "        else:\n",
    "            diff_scores = np.ones(len(self.nodes))\n",
    "            while not (diff_scores < threshold).all():\n",
    "                current_scores = np.array([n.score for n in self.nodes])\n",
    "                [n.update_score() for n in self.nodes]\n",
    "                new_scores = np.array([[n.score for n in self.nodes]])\n",
    "                diff_scores = np.abs(new_scores - current_scores)\n",
    "            return [(n.name, n.score) for n in self.nodes]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "introductory-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('딸기', 1.4671812436569796),\n",
       " ('파인애플', 0.5657013523694776),\n",
       " ('사과', 0.9838537217994482),\n",
       " ('바나나', 0.983839184134243)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1. convert a list of tokens into a dicionary of window information\n",
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "window_dict = make_pairs(tokens, window=2)\n",
    "\n",
    "# step2. update fnodes to each textrank node\n",
    "name2node = {name:trNode(name) for name in list(window_dict.keys())}\n",
    "#print(name2node)\n",
    "for node_name, node_fnodes in window_dict.items():\n",
    "    fnodes_ = [name2node[fnode] for fnode in node_fnodes]\n",
    "    name2node[node_name].update_fnodes(fnodes_)\n",
    "\n",
    "# step3. calculate node weight\n",
    "tr = textRank(list(name2node.values()))\n",
    "tr.update_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-dylan",
   "metadata": {},
   "source": [
    "### Function wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afraid-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_textrank(tokens, window=2):\n",
    "    # step1. convert a list of tokens into a dicionary of window information\n",
    "    window_dict = make_pairs(tokens, window)\n",
    "\n",
    "    # step2. update fnodes to each textrank node\n",
    "    name2node = {name:trNode(name) for name in list(window_dict.keys())}\n",
    "    #print(name2node)\n",
    "    for node_name, node_fnodes in window_dict.items():\n",
    "        fnodes_ = [name2node[fnode] for fnode in node_fnodes]\n",
    "        name2node[node_name].update_fnodes(fnodes_)\n",
    "\n",
    "    # step3. calculate node weight\n",
    "    tr = textRank(list(name2node.values()))\n",
    "    scores = tr.update_nodes()\n",
    "    df_scores_sorted = pd.DataFrame(scores,\n",
    "             columns = ['token', 'weight']).sort_values(by='weight', ascending=False)\n",
    "    \n",
    "    return df_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "automotive-burner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>데이터</td>\n",
       "      <td>9.027626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>데이터를</td>\n",
       "      <td>4.007262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>위한</td>\n",
       "      <td>3.312292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>계획이다</td>\n",
       "      <td>3.258675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>빅데이터</td>\n",
       "      <td>3.171702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>통해</td>\n",
       "      <td>3.162752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>활용</td>\n",
       "      <td>2.075149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>금융</td>\n",
       "      <td>2.067445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>과기정통부</td>\n",
       "      <td>2.057109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>등</td>\n",
       "      <td>2.030982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token    weight\n",
       "179    데이터  9.027626\n",
       "132   데이터를  4.007262\n",
       "232     위한  3.312292\n",
       "251   계획이다  3.258675\n",
       "331   빅데이터  3.171702\n",
       "43      통해  3.162752\n",
       "137     활용  2.075149\n",
       "296     금융  2.067445\n",
       "168  과기정통부  2.057109\n",
       "127      등  2.030982"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_article = '''\n",
    "과기정통부 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도 개방성 강화 이데일리 이재운 기자 국가 차원의 빅데이터 활용 시대가 열린다 새로운 산업 창출과 기존 산업의 변화에 이르는 혁신성장 을 위한 센터가 문을 연다 10개 분야에 걸쳐 데이터 경제 의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다 22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 빅데이터 플랫폼 및 센터 출범식 행사를 개최했다 유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다 10개 분야 100개 센터 3년간 1516억원 투입이미지 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다 문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호 보안 에 대한 중요성을 강조하기도 했다 이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산 구축하고 플랫폼은 이를 수집 분석 유통하는 역할을 담당한다 과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며 올해 우선 640억원 규모의 사업을 추진하고 있다 대상 분야는 금융 BC카드 환경 한국수자원공사 문화 한국문화정보원 교통 한국교통연구원 헬스케어 국립암센터 유통 소비 매일방송 통신 KT 중소기업 더존비즈온 지역경제 경기도청 산림 한국임업진흥원 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원 운영할 계획이다 이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다 주요 활용 전략 사례를 보면 빅데이터 활용을 통해 신 시장 을 창출하는 방안을 담고 있다 금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다 유통 소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를 문화 플랫폼은 문화 예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다 의료비 절감 헬스케어 과 기업의 매출 향상을 통한 산업 육성 통신 산림 등도 눈길을 끈다 과기정통부 제공 2021년까지 5100여종 데이터 구축 AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산 구축하고 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산 구축해 시장에 공급할 계획이다 특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고 품질관리기준도 마련해 운영한다 기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다 센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고 센터에 축적된 데이터도 계속 외부와 개방 공유하며 최신 연속성을 확보한다는 계획이다 100개 센터에서 수집된 데이터를 융합 분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다 다양한 분석 도구는 물론 인공지능 AI 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다 이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고 데이터 보유와 관리에 대한 체계 거버넌스 를 논의하는 데이터 얼라이언스 를 구성해 보다 안전하게 이용하는 방안도 마련했다 유영민 과기정통부 장관은 오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리 라며 세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다 고 밝혔다 이재운\n",
    "'''\n",
    "test_article_tokens = test_article.split()\n",
    "article_textrank = compute_textrank(test_article_tokens)\n",
    "article_textrank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "played-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>데이터</td>\n",
       "      <td>9.181882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>데이터를</td>\n",
       "      <td>4.340775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>통해</td>\n",
       "      <td>3.751861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>계획이다</td>\n",
       "      <td>3.414695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>위한</td>\n",
       "      <td>3.342863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>빅데이터</td>\n",
       "      <td>3.232621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>과기정통부</td>\n",
       "      <td>2.292451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>등</td>\n",
       "      <td>2.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>활용</td>\n",
       "      <td>2.076501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>플랫폼</td>\n",
       "      <td>2.060321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token    weight\n",
       "179    데이터  9.181882\n",
       "132   데이터를  4.340775\n",
       "43      통해  3.751861\n",
       "251   계획이다  3.414695\n",
       "232     위한  3.342863\n",
       "331   빅데이터  3.232621\n",
       "168  과기정통부  2.292451\n",
       "127      등  2.109018\n",
       "137     활용  2.076501\n",
       "11     플랫폼  2.060321"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_textrank = compute_textrank(test_article_tokens,\n",
    "                                   window=5)\n",
    "article_textrank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-modern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-member",
   "metadata": {},
   "source": [
    "# TextRank using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "known-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "marked-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'딸기': ['바나나', '파인애플', '사과'],\n",
       " '파인애플': ['딸기'],\n",
       " '사과': ['바나나', '딸기'],\n",
       " '바나나': ['딸기', '사과']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_dict = make_pairs(tokens, 2)\n",
    "window_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sonic-irrigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('딸기', '바나나'),\n",
       " ('딸기', '파인애플'),\n",
       " ('딸기', '사과'),\n",
       " ('파인애플', '딸기'),\n",
       " ('사과', '바나나'),\n",
       " ('사과', '딸기'),\n",
       " ('바나나', '딸기'),\n",
       " ('바나나', '사과')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_pairs = [(k,vv) for k,v in window_dict.items() for vv in v]\n",
    "node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "conventional-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.diamond_graph()\n",
    "graph.clear()\n",
    "\n",
    "vocab = list(window_dict.keys())\n",
    "graph.add_nodes_from(vocab)\n",
    "graph.add_edges_from(node_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "married-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nx.pagerank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "significant-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'딸기': 0.3667352990529792,\n",
       " '파인애플': 0.14140875554444032,\n",
       " '사과': 0.2459279727012903,\n",
       " '바나나': 0.24592797270129033}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-modem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aboriginal-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>데이터</th>\n",
       "      <td>0.024196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>데이터를</th>\n",
       "      <td>0.010742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>위한</th>\n",
       "      <td>0.008880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>계획이다</th>\n",
       "      <td>0.008735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>빅데이터</th>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>통해</th>\n",
       "      <td>0.008479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>활용</th>\n",
       "      <td>0.005563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금융</th>\n",
       "      <td>0.005542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>과기정통부</th>\n",
       "      <td>0.005515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>등</th>\n",
       "      <td>0.005444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "데이터    0.024196\n",
       "데이터를   0.010742\n",
       "위한     0.008880\n",
       "계획이다   0.008735\n",
       "빅데이터   0.008502\n",
       "통해     0.008479\n",
       "활용     0.005563\n",
       "금융     0.005542\n",
       "과기정통부  0.005515\n",
       "등      0.005444"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_dict = make_pairs(test_article.split(), 2)\n",
    "node_pairs = [(k,vv) for k,v in window_dict.items() for vv in v]\n",
    "\n",
    "graph = nx.diamond_graph()\n",
    "graph.clear()\n",
    "\n",
    "vocab = list(window_dict.keys())\n",
    "graph.add_nodes_from(vocab)\n",
    "graph.add_edges_from(node_pairs)\n",
    "scores = nx.pagerank(graph)\n",
    "\n",
    "pd.DataFrame(scores, index=[0]).T.sort_values(by=0, ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-departure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-teaching",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "selective-alaska",
   "metadata": {},
   "source": [
    "# Simplified TextRank 2\n",
    "- applying `window_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "\n",
    "nodes = list(set(tokens))\n",
    "vocab = nodes\n",
    "vocab2idx = {k:i for (i,k) in enumerate(nodes)}\n",
    "idx2vocab = {i:k for (i,k) in enumerate(nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "piano-belgium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'딸기': 0, '파인애플': 1, '사과': 2, '바나나': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constant-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '딸기', 1: '파인애플', 2: '사과', 3: '바나나'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "lightweight-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기', '바나나', '사과', '딸기', '파인애플']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "organizational-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(tokens, window=2):\n",
    "    \n",
    "    nodes = list(set(tokens))\n",
    "    vocab = nodes\n",
    "    vocab2idx = {k:i for (i,k) in enumerate(nodes)}\n",
    "    idx2vocab = {i:k for (i,k) in enumerate(nodes)}\n",
    "    \n",
    "    idx = list(idx2vocab.keys())\n",
    "    #print(idx)\n",
    "    \n",
    "    res_dict = {k:[] for k in vocab}\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        #print(token)\n",
    "        leng = len(tokens)\n",
    "        \n",
    "        min_idx = max(0, i-window+1)\n",
    "        max_idx = min(leng, i+window)\n",
    "        \n",
    "        for t in tokens[min_idx:max_idx]:  \n",
    "            if t != token:\n",
    "                res_dict[token].append(t)\n",
    "    \n",
    "    print('with duplicates', res_dict)\n",
    "    res_dict = {k:list(set(v)) for k, v in res_dict.items()}\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respective-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기', '바나나', '사과', '딸기', '파인애플']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "worst-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplicates {'딸기': ['바나나', '사과', '파인애플'], '파인애플': ['딸기'], '사과': ['바나나', '딸기'], '바나나': ['딸기', '사과']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'딸기': ['바나나', '파인애플', '사과'],\n",
       " '파인애플': ['딸기'],\n",
       " '사과': ['바나나', '딸기'],\n",
       " '바나나': ['딸기', '사과']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pairs = make_pairs(tokens)\n",
    "token_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "miniature-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplicates {'딸기': ['바나나', '사과', '파인애플', '바나나', '사과'], '파인애플': ['딸기', '바나나'], '사과': ['바나나', '딸기', '딸기', '바나나'], '바나나': ['딸기', '사과', '파인애플', '딸기', '사과']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'딸기': ['바나나', '파인애플', '사과'],\n",
       " '파인애플': ['딸기', '바나나'],\n",
       " '사과': ['바나나', '딸기'],\n",
       " '바나나': ['딸기', '파인애플', '사과']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2 = ['딸기', '바나나', '사과', '딸기', '파인애플', '바나나', '딸기', '사과', '바나나']\n",
    "make_pairs(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-springfield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "improving-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "strawberry_fnodes = token_pairs['딸기']\n",
    "banana_fnodes = token_pairs['바나나']\n",
    "apple_fnodes = token_pairs['사과']\n",
    "pineapple_fnodes = token_pairs['파인애플']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "sudden-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "strawberry_score = 1\n",
    "banana_score = 1\n",
    "apple_score = 1\n",
    "pineapple_score = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "entertaining-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_score(t_pairs):\n",
    "    \n",
    "    token_names = list(t_pairs.keys())\n",
    "    token_lengths = [len(v) for v in list(t_pairs.values())]\n",
    "    \n",
    "    token_scores = [1] * len(token_names)\n",
    "    token_powers = [token_scores[i]/len(t_pairs[token]) for (i, token)\\\n",
    "                   in enumerate(token_names)]\n",
    "    name_power_dict = {n:p for n,p in zip(token_names, token_powers)}\n",
    "    \n",
    "    diff_scores = np.array([1, 1, 1, 1])\n",
    "    \n",
    "    # update score\n",
    "    while not np.abs(diff_scores < 0.0001).all():\n",
    "        # update information\n",
    "        token_powers = [token_scores[i]/len(t_pairs[token]) for (i, token)\\\n",
    "                   in enumerate(token_names)]\n",
    "        name_power_dict = {n:p for n,p in zip(token_names, token_powers)}\n",
    "        prev_scores = token_scores.copy()\n",
    "        \n",
    "        for i, (k, v) in enumerate(t_pairs.items()):\n",
    "            #print(k, v)\n",
    "            tot = 0\n",
    "            for node in v:\n",
    "                tot += (name_power_dict[node])\n",
    "            token_scores[i] = tot\n",
    "        \n",
    "        diff_scores = np.array(token_scores) - np.array(prev_scores)\n",
    "\n",
    "#        diff_scores = np.array(prev_scores) - np.array(token_scores)\n",
    "    \n",
    "    return token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "retired-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.000024679409045, 1.000024679409045, 1.4999090282268144, 0.5000416129550959]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_score(token_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-edmonton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "political-awareness",
   "metadata": {},
   "source": [
    "# Simplified TextRank 3\n",
    "- tutor version\n",
    "    - window sliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "continental-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)\n",
    "weighted_edge = np.zeros((vocab_len, vocab_len),\n",
    "                        dtype=np.float32)\n",
    "score = np.ones((vocab_len), dtype=np.float32)\n",
    "window_size = 3\n",
    "covered_co_occurrences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "instructional-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['딸기', '바나나', '사과']\n"
     ]
    }
   ],
   "source": [
    "for window_start in range(0, len(tokens) - window_size + 1):\n",
    "    window = tokens[window_start : window_start + window_size]\n",
    "    print(window)\n",
    "    for i in range(window_size):\n",
    "        for j in range(i+1, window_size):\n",
    "            if (window[i] in vocab2idx.keys()) and (window[j] in vocab2idx.keys()):\n",
    "                index_of_i = window_start + i\n",
    "                index_of_j = window_start + j\n",
    "                \n",
    "                if [index_of_i, index_of_j] not in covered_co_occurrences:\n",
    "                    weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                    covered_co_occurrences.append([index_of_i, index_of_j])        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "subjective-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-afternoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-activation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
