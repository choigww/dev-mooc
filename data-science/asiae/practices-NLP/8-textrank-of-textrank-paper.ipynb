{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divine-stuff",
   "metadata": {},
   "source": [
    "# TextRank 논문 텍스트를 TextRank로 분석하기."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-ordinary",
   "metadata": {},
   "source": [
    "## TextRank 알고리즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worth-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(tokens, window=2):\n",
    "    \n",
    "    nodes = list(set(tokens))\n",
    "    vocab = nodes\n",
    "    vocab2idx = {k:i for (i,k) in enumerate(nodes)}\n",
    "    idx2vocab = {i:k for (i,k) in enumerate(nodes)}\n",
    "    \n",
    "    idx = list(idx2vocab.keys())\n",
    "    #print(idx)\n",
    "    \n",
    "    res_dict = {k:[] for k in vocab}\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        #print(token)\n",
    "        leng = len(tokens)\n",
    "        \n",
    "        min_idx = max(0, i-window+1)\n",
    "        max_idx = min(leng, i+window)\n",
    "        \n",
    "        for t in tokens[min_idx:max_idx]:  \n",
    "            if t != token:\n",
    "                res_dict[token].append(t)\n",
    "    \n",
    "    #print('with duplicates', res_dict)\n",
    "    res_dict = {k:list(set(v)) for k, v in res_dict.items()}\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integrated-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trNode:\n",
    "    def __init__(self, name, damping_factor=0.85):\n",
    "        self.name = name\n",
    "        self.d = damping_factor\n",
    "        self.fnodes = []\n",
    "        \n",
    "        # initial score\n",
    "        self.score = 1\n",
    "        \n",
    "    def update_score(self):\n",
    "        # update node score\n",
    "        input_weights = [fnode.score/len(fnode.fnodes) for fnode in self.fnodes]\n",
    "        self.score = (1-self.d) + self.d * sum(input_weights)\n",
    "        \n",
    "    def update_fnodes(self, nodes):\n",
    "        for node in nodes:\n",
    "            self.fnodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fossil-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textRank:\n",
    "    def __init__(self, nodes):\n",
    "        self.nodes = nodes\n",
    "        \n",
    "    def update_nodes(self, times=None, threshold = 0.0001):\n",
    "        # limited times\n",
    "        if times:\n",
    "            for i in range(times):\n",
    "                [n.update_score() for n in self.nodes]\n",
    "                return [(n.name, n.score) for n in self.nodes]\n",
    "        # until convergence (< threshold)\n",
    "        else:\n",
    "            diff_scores = np.ones(len(self.nodes))\n",
    "            while not (diff_scores < threshold).all():\n",
    "                current_scores = np.array([n.score for n in self.nodes])\n",
    "                [n.update_score() for n in self.nodes]\n",
    "                new_scores = np.array([[n.score for n in self.nodes]])\n",
    "                diff_scores = np.abs(new_scores - current_scores)\n",
    "            return [(n.name, n.score) for n in self.nodes]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "previous-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_textrank(tokens, window=2):\n",
    "    # step1. convert a list of tokens into a dicionary of window information\n",
    "    window_dict = make_pairs(tokens, window)\n",
    "\n",
    "    # step2. update fnodes to each textrank node\n",
    "    name2node = {name:trNode(name) for name in list(window_dict.keys())}\n",
    "    #print(name2node)\n",
    "    for node_name, node_fnodes in window_dict.items():\n",
    "        fnodes_ = [name2node[fnode] for fnode in node_fnodes]\n",
    "        name2node[node_name].update_fnodes(fnodes_)\n",
    "\n",
    "    # step3. calculate node weight\n",
    "    tr = textRank(list(name2node.values()))\n",
    "    scores = tr.update_nodes()\n",
    "    df_scores_sorted = pd.DataFrame(scores,\n",
    "             columns = ['token', 'weight']).sort_values(by='weight', ascending=False)\n",
    "    \n",
    "    return df_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-spectacular",
   "metadata": {},
   "source": [
    "## Preprocess for Paper text\n",
    "- nltk 영문 stopwords 적용\n",
    "- 논문 특성상 나타나는 문자열 특성 파악\n",
    "    - 전처리 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-interaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/choigww/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# download stopwords for english\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-vienna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-rebel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "varying-security",
   "metadata": {},
   "source": [
    "## TextRank application to TextRank paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-universe",
   "metadata": {},
   "source": [
    "### Abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "opposed-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications. In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = '''\n",
    "In this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications. In particular, we propose two innova- tive unsupervised methods for keyword and sentence extraction, and show that the results obtained com- pare favorably with previously published results on established benchmarks.\n",
    "'''\n",
    "abstract = abstract.replace(\"- \", \"\")\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "basic-fitness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>results</td>\n",
       "      <td>1.678049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>1.613064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>show</td>\n",
       "      <td>1.586814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>introduce</td>\n",
       "      <td>1.144579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>textrank</td>\n",
       "      <td>1.067155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>graph</td>\n",
       "      <td>1.013384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>propose</td>\n",
       "      <td>0.994907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>two</td>\n",
       "      <td>0.994809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>particular</td>\n",
       "      <td>0.993202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>innovative</td>\n",
       "      <td>0.992872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token    weight\n",
       "6      results  1.678049\n",
       "0        model  1.613064\n",
       "31        show  1.586814\n",
       "5    introduce  1.144579\n",
       "7     textrank  1.067155\n",
       "10       graph  1.013384\n",
       "19     propose  0.994907\n",
       "20         two  0.994809\n",
       "16  particular  0.993202\n",
       "22  innovative  0.992872"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'[^a-zA-Z0-9]'\n",
    "abstract_tokens = re.sub(pattern, ' ',abstract).split()\n",
    "abstract_tokens_sw = [token.lower() for token in abstract_tokens\\\n",
    "                         if token.lower() not in stopwords]\n",
    "article_textrank = compute_textrank(abstract_tokens_sw)\n",
    "article_textrank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-certification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continued-doctor",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "proud-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = '''\n",
    "Graph-based ranking algorithms like Kleinberg’s HITS algorithm (Kleinberg, 1999) or Google’s PageRank (Brin and Page, 1998) have been success- fully used in citation analysis, social networks, and the analysis of the link-structure of the World Wide Web. Arguably, these algorithms can be singled out as key elements of the paradigm-shift triggered in the field of Web search technology, by providing a Web page ranking mechanism that relies on the col- lective knowledge of Web architects rather than in- dividual content analysis of Web pages. In short, a graph-based ranking algorithm is a way of deciding on the importance of a vertex within a graph, by tak- ing into account global information recursively com- puted from the entire graph, rather than relying only on local vertex-specific information.\n",
    "Applying a similar line of thinking to lexical or semantic graphs extracted from natural language documents, results in a graph-based ranking model that can be applied to a variety of natural language processing applications, where knowledge drawn from an entire text is used in making local rank- ing/selection decisions. Such text-oriented ranking methods can be applied to tasks ranging from auto- mated extraction of keyphrases, to extractive summa- rization and word sense disambiguation (Mihalcea et al., 2004).\n",
    "In this paper, we introduce the TextRank graph- based ranking model for graphs extracted from nat- ural language texts. We investigate and evaluate the application of TextRank to two language processing tasks consisting of unsupervised keyword and sen-\n",
    "tence extraction, and show that the results obtained with TextRank are competitive with state-of-the-art systems developed in these areas.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "smooth-lotus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ranking</td>\n",
       "      <td>3.439573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>web</td>\n",
       "      <td>3.300161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>graph</td>\n",
       "      <td>2.278878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>textrank</td>\n",
       "      <td>2.176259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>analysis</td>\n",
       "      <td>2.068224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>language</td>\n",
       "      <td>1.751236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>extraction</td>\n",
       "      <td>1.583042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>information</td>\n",
       "      <td>1.553126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tasks</td>\n",
       "      <td>1.446419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kleinberg</td>\n",
       "      <td>1.424731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token    weight\n",
       "93      ranking  3.439573\n",
       "82          web  3.300161\n",
       "61        graph  2.278878\n",
       "85     textrank  2.176259\n",
       "88     analysis  2.068224\n",
       "74     language  1.751236\n",
       "7    extraction  1.583042\n",
       "51  information  1.553126\n",
       "40        tasks  1.446419\n",
       "76    kleinberg  1.424731"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro = intro.replace(\"- \", \"\")\n",
    "pattern = r'[^a-zA-Z0-9]'\n",
    "intro_tokens = re.sub(pattern, ' ',intro).split()\n",
    "intro_tokens_sw = [token.lower() for token in intro_tokens\\\n",
    "                         if token.lower() not in stopwords]\n",
    "article_textrank = compute_textrank(intro_tokens_sw)\n",
    "article_textrank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-administration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-teach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
