{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fantastic-eclipse",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "composite-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = 1 : SPAM\n",
    "# label = 0 : NORMAL\n",
    "training_set = [\n",
    "    ['me free lottery', 1],\n",
    "    ['free get free you', 1],\n",
    "    ['you free scholarship', 0],\n",
    "    ['free to contact me', 0],\n",
    "    ['you won award', 0],\n",
    "    ['you ticket lottery', 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "returning-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'me': [1, 1],\n",
       "             'free': [2, 3],\n",
       "             'lottery': [0, 2],\n",
       "             'get': [0, 1],\n",
       "             'you': [2, 2],\n",
       "             'scholarship': [1, 0],\n",
       "             'to': [1, 0],\n",
       "             'contact': [1, 0],\n",
       "             'won': [1, 0],\n",
       "             'award': [1, 0],\n",
       "             'ticket': [0, 1]})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "doc_cnt0 = 0 # normal count\n",
    "doc_cnt1 = 0 # spam count\n",
    "\n",
    "wordfreq = defaultdict(lambda : [0, 0])\n",
    "\n",
    "for doc, label in training_set:\n",
    "    words = doc.split()\n",
    "    for word in words:\n",
    "        wordfreq[word][label] += 1\n",
    "        \n",
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, (cnt0, cnt1) in wordfreq.items():\n",
    "    doc_cnt0 += cnt0 # normal count\n",
    "    doc_cnt1 += cnt1 # spam count\n",
    "    \n",
    "doc_cnt0, doc_cnt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'me': [0.13636363636363635, 0.13636363636363635],\n",
       "             'free': [0.22727272727272727, 0.3181818181818182],\n",
       "             'lottery': [0.045454545454545456, 0.22727272727272727],\n",
       "             'get': [0.045454545454545456, 0.13636363636363635],\n",
       "             'you': [0.22727272727272727, 0.22727272727272727],\n",
       "             'scholarship': [0.13636363636363635, 0.045454545454545456],\n",
       "             'to': [0.13636363636363635, 0.045454545454545456],\n",
       "             'contact': [0.13636363636363635, 0.045454545454545456],\n",
       "             'won': [0.13636363636363635, 0.045454545454545456],\n",
       "             'award': [0.13636363636363635, 0.045454545454545456],\n",
       "             'ticket': [0.045454545454545456, 0.13636363636363635]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob_dict = wordfreq.copy()\n",
    "k = 0.5\n",
    "\n",
    "for key, (cnt0, cnt1) in wordfreq.items():\n",
    "    # 스팸메일일 때 해당 단어가 출현할 확률\n",
    "    prob_word_given_spam = (k + cnt1) / (2 * k + doc_cnt1)\n",
    "    \n",
    "    # 일반메일일 때 해당 단어가 출현할 확률\n",
    "    prob_word_given_norm = (k + cnt0) / (2 * k + doc_cnt0)\n",
    "    \n",
    "    cond_prob_dict[key] = [prob_word_given_norm, prob_word_given_spam]\n",
    "    \n",
    "cond_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-ontario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "horizontal-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'me': [-1.9924301646902063, -1.9924301646902063],\n",
       " 'free': [-1.4816045409242156, -1.1451323043030026],\n",
       " 'lottery': [-3.0910424533583156, -1.4816045409242156],\n",
       " 'get': [-3.0910424533583156, -1.9924301646902063],\n",
       " 'you': [-1.4816045409242156, -1.4816045409242156],\n",
       " 'scholarship': [-1.9924301646902063, -3.0910424533583156],\n",
       " 'to': [-1.9924301646902063, -3.0910424533583156],\n",
       " 'contact': [-1.9924301646902063, -3.0910424533583156],\n",
       " 'won': [-1.9924301646902063, -3.0910424533583156],\n",
       " 'award': [-1.9924301646902063, -3.0910424533583156],\n",
       " 'ticket': [-3.0910424533583156, -1.9924301646902063]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "log_cond_prob_dict = {key:[np.log(v1), np.log(v2)] for (key,[v1, v2]) in cond_prob_dict.items()}\n",
    "log_cond_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-trout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_norm = (doc_cnt0) / (doc_cnt0 + doc_cnt1)\n",
    "prob_spam = 1 - prob_norm\n",
    "\n",
    "prob_norm, prob_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-cardiff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "varying-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "prob_norm_given_free_lottery_numerator = np.exp(\\\n",
    "                log_cond_prob_dict['free'][0] + log_cond_prob_dict['lottery'][0] + np.log(prob_norm))\n",
    "\n",
    "prob_spam_given_free_lottery_numerator = np.exp(\\\n",
    "                log_cond_prob_dict['free'][1] + log_cond_prob_dict['lottery'][1] + np.log(prob_spam))\n",
    "\n",
    "prob_normspam_given_free_lottery_numerator = prob_norm_given_free_lottery_numerator +\\\n",
    "                                                    prob_spam_given_free_lottery_numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pacific-dylan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12500000000000008, 0.8749999999999999)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_norm_given_free_lottery = prob_norm_given_free_lottery_numerator / prob_normspam_given_free_lottery_numerator\n",
    "prob_spam_given_free_lottery = prob_spam_given_free_lottery_numerator / prob_normspam_given_free_lottery_numerator\n",
    "\n",
    "prob_norm_given_free_lottery, prob_spam_given_free_lottery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-pacific",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bridal-frame",
   "metadata": {},
   "source": [
    "## Naive Bayesian 스팸 탐지 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "grateful-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spam_NB(training_set, email_words, unseen_word_accept=True):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    doc_cnt0 = 0 # normal count\n",
    "    doc_cnt1 = 0 # spam count\n",
    "\n",
    "    wordfreq = defaultdict(lambda : [0, 0])\n",
    "\n",
    "    for doc, label in training_set:\n",
    "        words = doc.split()\n",
    "        for word in words:\n",
    "            wordfreq[word][label] += 1\n",
    "    \n",
    "    \n",
    "    # word check\n",
    "    for word in email_words:\n",
    "        if word not in wordfreq.keys():\n",
    "            if not unseen_word_accept:\n",
    "                assert word not in email_words, \"Invalid word list.\" # assert\n",
    "            wordfreq[word] = [1, 1] # set 50% / 50%\n",
    "                \n",
    "    \n",
    "    for key, (cnt0, cnt1) in wordfreq.items():\n",
    "        doc_cnt0 += cnt0 # normal count\n",
    "        doc_cnt1 += cnt1 # spam count\n",
    "    \n",
    "    cond_prob_dict = wordfreq.copy()\n",
    "    k = 0.5\n",
    "    prob_norm = (doc_cnt0) / (doc_cnt0 + doc_cnt1)\n",
    "    prob_spam = 1 - prob_norm\n",
    "    \n",
    "    # Laplace Smoothing 적용\n",
    "    for key, (cnt0, cnt1) in wordfreq.items():\n",
    "        # 스팸메일일 때 해당 단어가 출현할 확률\n",
    "        prob_word_given_spam = (k + cnt1) / (2 * k + doc_cnt1)\n",
    "\n",
    "        # 일반메일일 때 해당 단어가 출현할 확률\n",
    "        prob_word_given_norm = (k + cnt0) / (2 * k + doc_cnt0)\n",
    "        \n",
    "        # cond_prob_dict 업데이트\n",
    "        cond_prob_dict[key] = [prob_word_given_norm, prob_word_given_spam]\n",
    "    \n",
    "    # ㅣog 변환 - 언더플로우 방지\n",
    "    log_cond_prob_dict = {key:[np.log(v1), np.log(v2)] for (key,[v1, v2]) in cond_prob_dict.items()}\n",
    "    \n",
    "    #print(log_cond_prob_dict)\n",
    "    \n",
    "    # 계산\n",
    "    numerators_norm_given_words = np.exp(np.sum([log_cond_prob_dict[word][0] for word in email_words]))\n",
    "    numerators_spam_given_words = np.exp(np.sum([log_cond_prob_dict[word][1] for word in email_words]))\n",
    "    denominator = numerators_norm_given_words + numerators_spam_given_words\n",
    "    \n",
    "    #print(numerators_spam_given_words, denominator)\n",
    "    \n",
    "    prob_norm_given_words = numerators_norm_given_words / denominator\n",
    "    prob_spam_given_words = 1 - prob_norm_given_words\n",
    "    \n",
    "    return round(prob_spam_given_words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-thing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-briefs",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "appointed-monaco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['me', 'award'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "waiting-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "coordinated-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery', 'ticket'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "lasting-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery', 'ticket', 'me'], False) # me는 정상, 스팸메일 출현빈도가 동일하므로 정보량 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "billion-theorem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery', 'ticket', 'me', 'award'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "brilliant-manner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery', 'ticket', 'aha', 'gogo'], # aha, gogo는 정상, 스팸메일 출현빈도 동일하므로 정보량X\n",
    "               True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "verbal-following",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid word list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-ec50fbea865c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m detect_spam_NB(training_set,\n\u001b[1;32m      2\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0;34m'free'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lottery'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ticket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gogo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-8c54e11f5acf>\u001b[0m in \u001b[0;36mdetect_spam_NB\u001b[0;34m(training_set, email_words, unseen_word_accept)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print(wordfreq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memail_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Invalid word list.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid word list."
     ]
    }
   ],
   "source": [
    "detect_spam_NB(training_set,\n",
    "              ['free', 'lottery', 'ticket', 'aha', 'gogo'],\n",
    "              False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-straight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-leadership",
   "metadata": {},
   "source": [
    "# Scikit-learn Multinomial Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "standing-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "caring-miracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "obvious-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "saving-japanese",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "rural-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "closed-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), # DTM - Document-Term Matrix\n",
    "                     ('tfidf', TfidfTransformer()), # tf-idf 계산\n",
    "                     ('clf', MultinomialNB())]) # tf-idf 수치 기반으로 NB classification\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,\n",
    "                        twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "coordinate-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "universal-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "linear-average",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 예측한 문서 카테고리\n",
    "twenty_train.target_names[predicted[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "announced-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 문서 카테고리\n",
    "twenty_train.target_names[twenty_test.target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "characteristic-white",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handmade-equality",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "downtown-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'vect__ngram_range' : [(1, 1), (1, 2)], # (1,1) = unigram, (1,2) = bigram\n",
    "              'tfidf__use_idf' : (True, False),\n",
    "              'clf__alpha' : (0.1, 0.25, 0.5, 0.75, 1.0)\n",
    "             }\n",
    "\n",
    "gscv_clf = GridSearchCV(text_clf, parameters,\n",
    "                       n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "sound-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.0min finished\n"
     ]
    }
   ],
   "source": [
    "gscv_clf_fit = gscv_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "continuing-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017146241794632"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "paperback-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "demonstrated-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8263409453000531"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = gscv_clf.best_estimator_.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-syria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-track",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
