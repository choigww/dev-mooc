{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quizzes\n",
    "### Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What back propagation is usually used for in neural networks?\n",
    "* To propagate signal through network from input to output only\n",
    "* Select gradient update direction by flipping a coin\n",
    "* Make several random perturbations of parameters and go back to the best one\n",
    "* **To calculate gradient of the loss function with respect to the parameters of the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we've trained a RandomForest model with 100 trees. Consider two cases:\n",
    "\n",
    "1. We drop the first tree in the model\n",
    "2. We drop the last tree in the model\n",
    "\n",
    "We then compare models performance on the train set. Select the right answer.\n",
    "\n",
    "* In the case 1 performance will drop more than in the case 2\n",
    "* **In the case 1 performance will be roughly the same as in the case 2**\n",
    "* In the case 1 performance will drop less than in the case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we've trained a GBDT model with 100 trees with a fairly large learning rate. Consider two cases:\n",
    "\n",
    "1. We drop the first tree in the model\n",
    "2. We drop the last tree in the model\n",
    "\n",
    "We then compare models performance on the train set. Select the right answer.\n",
    "\n",
    "* **In the case 1 performance will drop more than in the case 2**\n",
    "* In the case 1 performance will be roughly the same as in the case 2\n",
    "* In the case 1 performance will drop less than in the case 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider two cases:\n",
    "\n",
    "1. We fit two RandomForestClassifiers 500 trees each and average their predicted probabilities on the test set.\n",
    "2. We fit a RandomForestClassifier with 1000 trees and use it to get test set probabilities.\n",
    "\n",
    "All hyperparameters except number of trees are the same for all models. Select the right answer.\n",
    "\n",
    "* **The quality of predictions in the case 1 will be roughly the same as the quality of the predictions in the case 2**\n",
    "* The quality of predictions in the case 1 will be lower than the quality of the predictions in the case 2\n",
    "* The quality of predictions in the case 1 will be higher than the quality of the predictions in the case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which library provides the most convenient way to perfrom matrix multiplication?\n",
    "\n",
    "* **Numpy**\n",
    "* Pandas\n",
    "* Sklearn\n",
    "* XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which libraries contain implementation of linear models?\n",
    "\n",
    "* Pandas\n",
    "* Numpy\n",
    "* **Sklearn**\n",
    "* Matplotlib\n",
    "* tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which library (or libraries) are used to train a neural network?\n",
    "\n",
    "* Numpy\n",
    "* **Pytorch**\n",
    "* Matplotlib\n",
    "* **Keras**\n",
    "* **Tensorflow**\n",
    "* T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the correct statements about the RandomForest and GBDT models.\n",
    "\n",
    "* **In GBDT each new tree is built to improve the previous trees.**\n",
    "  * `Since each tree is independent from other trees`\n",
    "* Trees in GBDT can be constructed in parallel (that is how XGBoost makes use of all your cores)\n",
    "  * `No, we need to build trees in sequential manner. In XGBoost multiple cores are used to build single tree.`\n",
    "* In RandomForest each new tree is built to improve the previous trees.\n",
    "  * `No, every tree is independent.`\n",
    "* **Trees in RandomForest can be constructed in parallel (that is how RandomForest from sklearn makes use of all your cores)**\n",
    "  * `The idea of boosting is to correct errors of previously learned models`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What type does a feature with values: `[‘low’, ‘middle’, ‘high’]` most likely have?\n",
    "\n",
    "* Categorical\n",
    "* Numeric\n",
    "* Coordinates\n",
    "* **Ordinal (ordered categorical)**\n",
    "* Text\n",
    "* Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose you have a dataset X, and a version of X where each feature has been standard scaled.\n",
    "For which model types training or testing quality can be much different depending on the choice of the dataset?\n",
    "\n",
    "* **Neural network**\n",
    "* Random Forest\n",
    "* **Nearest neighbours**\n",
    "* GBDT\n",
    "  * Tree-based methods split features using simple thresholds and they usually are insensitive to monotonic transforms of the data, so GBDT will perform more or less the same on the both datasets.\n",
    "* **Linear models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we want to fit a GBDT model to a data with a categorical feature. \n",
    "We need to somehow encode the feature. Which of the following statements are true?\n",
    "\n",
    "* One-hot encoding is always better than label encoding\n",
    "* **Depending on the dataset either of label encoder or one-hot encoder could be better**\n",
    "* Label encoding is always better to use than one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can be useful to do about missing values?\n",
    "\n",
    "* Impute with feature variance\n",
    "* **Nothing, but use a model that can deal with them out of the box**\n",
    "* **Replace them with a constant (-1/-999/etc.)**\n",
    "* Apply standard scaler\n",
    "* **Remove rows with missing values**\n",
    "* **Reconstruct them (for example train a model to predict the missing values)**\n",
    "* **Impute with a feature mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "### Feature preprocessing and generation with respect to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose we have a feature with all the values between 0 and 1 except few outliers larger than 1. \n",
    "What can help us to *decrease outliers' influence on non-tree models*?\n",
    "\n",
    "* **Apply rank transform to the features**\n",
    "  * `Yes, because after applying rank distance between all adjacent objects in a sorted array is 1, outliers now will be very close to other samples.`\n",
    "* **[Winsorization](https://en.wikipedia.org/wiki/Winsorizing)**\n",
    "  * `The main purpose of winsorization is to remove outliers by clipping feature's values.`\n",
    "* StandardScaler\n",
    "* MinMaxScaler\n",
    "* **Apply $np.log1p(x)$ transform to the data**\n",
    "  * `This transformation is non-linear and will move outliers relatively closer to other samples.`\n",
    "* **Apply $np.sqrt(x)$ transform to the data**\n",
    "  * `This transformation is non-linear and will move outliers relatively closer to other samples.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose we fit a tree-based model. \n",
    "In which cases label encoding can be better to use than one-hot encoding?\n",
    "\n",
    "* **When the number of categorical features in the dataset is huge**\n",
    "  * `One-hot encoding a categorical feature with huge number of values can lead to (1) high memory consumption and (2) the case when non-categorical features are rarely used by model. You can deal with the 1st case if you employ sparse matrices. The 2nd case can occur if you build a tree using only a subset of features. For example, if you have 9 numeric features and 1 categorical with 100 unique values and you one-hot-encoded that categorical feature, you will get 109 features. If a tree is built with only a subset of features, initial 9 numeric features will rarely be used. In this case, you can increase the parameter controlling size of this subset. In xgboost it is called colsample_bytree, in sklearn's Random Forest max_features.`\n",
    "* **When categorical feature is ordinal**\n",
    "  * `Correct! Label encoding can lead to better quality if it preserves correct order of values. In this case a split made by a tree will divide the feature to values 'lower' and 'higher' that the value chosen for this split.`\n",
    "* **When we can come up with label encoder, that assigns close labels to similar (in terms of target) categories**\n",
    "  * `Correct! First, in this case tree will achieve the same quality with less amount of splits, and second, this encoding will help to treat rare categories.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose we fit a tree-based model on several categorical features.\n",
    "In which cases applying one-hot encoding can be better to use than label-encoding?\n",
    "\n",
    "* **If target dependence on the label encoded feature is very non-linear, i.e. values that are close to each other in the label encode feature correspond to target values that aren't close.**\n",
    "  * ` Correct! If this feature is important, a tree would try to make a lot of splits and select each feature' value in a category on its own. But because tree is build in a greedy way, it can be hard to select one important value in label encoded vector. This won't be the problem if you use OHE.`\n",
    "* When the feature have only two unique values\n",
    "  * `When the feature have only two unique values. Incorrect. In this case both one-hot encoding and label encoding will produce similar columns.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose we have a categorical feature and a linear model. \n",
    "We need to somehow encode this feature. Which of the following statements are true?\n",
    "\n",
    "* Label encoding is always better than one-hot encoding\n",
    "  * `Usually the dependence between the feature and the target is non-linear. In this case a linear model will not be able to utilize Label Encoded feature efficiently.`\n",
    "* One-hot encoding is always better than label encoding\n",
    "  * `Consider the toy example when the label encoded feature and the target are equal. In this case a linear model on this feature will have the perfect quality.`\n",
    "* **Depending on the dataset either of label encoder or one-hot encoder could be better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "### Feature extraction from text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF is applied to a matrix where each column represents a word, each row represents a document, and each value shows the number of times a particular word occurred in a particular document. Choose the correct statements.\n",
    "\n",
    "* **IDF scales features inversely proportionally to a number of word occurrences over documents**\n",
    "* IDF scales features proportional to the frequency of word’s occurrences\n",
    "* TF normalizes sum of the column values to 1\n",
    "* **TF normalizes sum of the row values to 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What of these methods can be used to preprocess texts?\n",
    "\n",
    "* **Stemming**\n",
    "* **Lemmatization**\n",
    "* Plumping\n",
    "* **Stopwords removal**\n",
    "* **Lowercase transformation**\n",
    "* Levenshteining\n",
    "* Plumbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main purpose of Lemmatization and Stemming?\n",
    "\n",
    "* To induce common word amplification standards to the most useful for machine learning algorithms form.\n",
    "* To reduce significance of common words.\n",
    "* **To reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.**\n",
    "* To remove words which are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To learn Word2vec embeddings we need ...\n",
    "\n",
    "* Labels for the documents in the corpora\n",
    "* GloVe embeddings\n",
    "* Labels for each word in the documents in the corpora\n",
    "  * `We only need words. `\n",
    "* **Text corpora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "### Feature extraction from text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select true statements about n-grams\n",
    "\n",
    "* Levenshteining should always be applied before computing n-grams\n",
    "* **N-grams features are typically sparse**\n",
    "  * `Correct. Ngrams deal with counts of words occurrences, and not every word can be found in a document. For example, if we count occurrences of words from an english dictionary in our everyday speech, a lot of words won't be there, and that is sparsity.\n",
    "`\n",
    "* **N-grams can help utilize local context around each word**\n",
    "  * `Correct, because ngrams encode sequences of words.`\n",
    "* N-grams always help increase significance of important words\n",
    "  * `No, ngrams deals with words occurrences and not their importance.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select true statements.\n",
    "\n",
    "* You do not need bag of words features in a competition if you have word2vec features.\n",
    "  * `Incorrect. Both approaches are valuable and you should try to utilize both of them.`\n",
    "* Meaning of each value in BOW matrix is unknown.\n",
    "  * `Incorrect. Meaning of a value in BOW matrix is the number of a word's occurrences in a document.`\n",
    "* **Semantically similar words usually have similar word2vec embeddings.**\n",
    "  * `Correct. This is one of the main benefits of w2v in competitions.`\n",
    "* **Bag of words usually produces longer vectors than Word2vec**\n",
    "  * `Correct! Number of features in Bag of words approach is usually equal to number of unique words, while number of features in w2v is restricted to a constant, like 300 or so.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose in a new competition we are given a dataset of 2D medical images. \n",
    "We want to extract image descriptors from a hidden layer of a neural network pretrained on the ImageNet dataset. We will then use extracted descriptors to train a simple logistic regression model to classify images from our dataset.<br>\n",
    "\n",
    "We consider to use two networks: ResNet-50 with imagenet accuracy of X and VGG-16 with imageNet accuracy of Y (X < Y). Select true statements.\n",
    "\n",
    "* Descriptors from ResNet-50 and from VGG-16 are always very similar in cosine distance.\n",
    "* For any image descriptors from the last hidden layer of ResNet-50 are the same as the descriptors from the last hidden layer of VGG-16.\n",
    "* **It is not clear what descriptors are better on our dataset. We should evaluate both.**\n",
    "* Descriptors from ResNet 50 will always be better than the ones from VGG-16 in our pipeline.\n",
    "* With one pretrained CNN model you can get only one vector of descriptors for an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation can be used at (1) train time (2) test time\n",
    "\n",
    "* False, True\n",
    "* True, False\n",
    "* **True, True**\n",
    "  * `Data augmentation can be used (1) to increase the amount of training data and (2) to average predictions for one augmented sample.`\n",
    "* False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
