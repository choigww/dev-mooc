{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In the previous missions, we learned how the linear regression model estimates the relationship between the feature columns and the target column and how we can use that for making predictions. In this mission and the next, we'll discuss the 2 most common ways for finding the optimal parameter values for a linear regression model. Each combination of unique parameter values forms a unique linear regression model, and the process of finding these optimal values is known as **model fitting**. Both approaches to model fitting we'll explore aim to minimize the following function:<br>\n",
    "\n",
    "$$MSE=\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_i}−y_i)^2$$\n",
    "\n",
    "This function is the mean squared error between the predicted labels made using a given model and the true labels. The problem of choosing a set of values that minimize or maximize another function is known as an [optimization problem](https://en.wikipedia.org/wiki/Mathematical_optimization).<br>\n",
    "\n",
    "To build intuition for the optimization process, let's start with a single parameter linear regression model:\n",
    "\n",
    "$$\\hat{y}=a_{1}x_1$$\n",
    "\n",
    "Note that this is different from a simple linear regression model, which actually has two parameters: $x_0$ and $x_1$.\n",
    "\n",
    "$$\\hat{y}=a_{1}x_1+a_0$$\n",
    "\n",
    "Let's use the `Gr Liv Area` column for the single parameter:\n",
    "\n",
    "$$\\hat{SalePrice}=a_1∗GrLivArea$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Variable Gradient Descent\n",
    "\n",
    "In the last screen's widget, we observed how the optimization function follows a curve with a minimum value. **This should remind you of our exploration of relative minimum values from calculus**. If you recall, \n",
    "1. we computed the critical points by calculating the curve's derivative, \n",
    "2. setting it equal to `0`, \n",
    "3. and finding the x value at this point. \n",
    "\n",
    "Unfortunately, this approach won't work when we have multiple parameter values **because minimizing one parameter value may increase another parameter's value**. In addition, while we can plot the MSE curve when we only have a single parameter we're trying to find and visually select the value that minimizes the MSE, this approach won't work when we have multiple parameter value because we can't visualize past 3 dimensions.<br>\n",
    "\n",
    "In this mission, we'll explore an iterative technique for solving this problem, known as **gradient descent**. The [gradient descent algorithm](https://en.wikipedia.org/wiki/Gradient_descent) works by iteratively trying different parameter values until the model with the lowest mean squared error is found. Gradient descent is a commonly used optimization technique for other models as well, like neural networks, which we'll explore later in this track.<br>\n",
    "\n",
    "Here's an overview of the gradient descent algorithm for a single parameter linear regression model:\n",
    "\n",
    "* select initial values for the parameter: a1\n",
    "* repeat until convergence (usually implemented with a max number of iterations):\n",
    "  * calculate the error (MSE) of model that uses current parameter value: $MSE(a_1)=\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y^{(i)}}−y^{(i)})2$\n",
    "  * calculate the derivative of the error (MSE) at the current parameter value: $\\frac{d}{da_1}MSE(a_1)$\n",
    "  * update the parameter value by subtracting the derivative times a constant (α, called the learning rate): $a_1:=a_1−\\alpha\\frac{d}{da_1}MSE(a_1)$\n",
    "\n",
    "In the last step of the algorithm, you'll notice we used we used := to indicate that the value on the right is assigned to the variable on the left. While in Python, we've used to the equals operator (`=`) for assignment, we've used it in math (=) to signify equality. For example, `a = 1` in Python assigns the value `1` to the variable `a`. In math, a=`1` asserts that a is equal to 1. In mathematical papers, sometimes ← is also used to signify assignment:\n",
    "\n",
    "$$a_1\\leftarrow a_1−\\alpha \\frac{d}{da_1}MSE(a_1)$$\n",
    "\n",
    "Selecting an appropriate initial parameter and learning rate will reduce the number of iterations required to converge, and is part of hyperparameter optimization. We won't dive into those techniques in this course and will instead focus on how the algorithm works. In the next screen, we'll unpack how to calculate the derivative of the error function at each iteration of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative Of The Cost Function\n",
    "\n",
    "In mathematical optimization, a function that we optimize through minimization is known as a **cost function** or sometime as the [loss function](https://en.wikipedia.org/wiki/Loss_function). Because we're trying to fit a single parameter model, we can replace with $\\hat{y^{(i)}}$ with $a_{1}(x_1)^{(i)}$ in the cost function:\n",
    "\n",
    "$$MSE(a1)=\\frac{1}{n}\\sum_{i=1}^{(i)}(a_{1}x_1^{(i)}−y^{(i)})^2$$\n",
    "\n",
    "In this screen, we'll apply calculus properties to simplify this derivative to something we can compute. **We encourage you to follow along using pencil and paper, and see if you can apply the properties we mention at each step to obtain the same result we did**. Note that while you'll probably never have to implement gradient descent yourself (as most packages have high performance implementations), understanding the math will help make it easier for you to debug when you run into issues.\n",
    "\n",
    "$$\n",
    "\\frac{d}{da_1} MSE(a_1) = \\frac{d}{da_1} \\frac{1}{n} \\sum_{i=1}^{n} (a_1x_1^{(i)} - y^{(i)} ) ^2\n",
    "$$\n",
    "\n",
    "By applying the [linearity of differentiation](https://en.wikipedia.org/wiki/Linearity_of_differentiation) property from calculus, we can bring the derivative term inside the summation:\n",
    "\n",
    "$$\n",
    "\\frac{d}{da_1} MSE(a_1) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{d}{da_1} (a_1x_1^{(i)} - y^{(i)} ) ^2\n",
    "$$\n",
    "\n",
    "We can apply both the power rule and the chain rule to simplify this. You can read more about the chain rule [here](https://en.wikipedia.org/wiki/Chain_rule) or observe how both are applied together [here](https://www.khanacademy.org/math/calculus-home/taking-derivatives-calc/chain-rule-calc/v/differentiating-powers-of-functions):\n",
    "\n",
    "$$\n",
    "\\frac{d}{da_1} MSE(a_1) = \\frac{1}{n} \\sum_{i=1}^{n} 2(a_1x_1^{(i)} - y^{(i)})  \\frac{d}{da_1} (a_1x_1^{(i)} - y^{(i)} )\n",
    "$$\n",
    "\n",
    "Because we're differentiating $a_{1}x_1^{(i)}−y^{(i)}$ with respect to $a_1$, we treat $y^{(i)}$ and $x_1^{(i)}$ as constants. $\\frac{d}{da_1}(a_1x_1^{(i)}−y^{(i)})$ then simplifies to just $x_1^{(i)}$:\n",
    "\n",
    "\n",
    "$$\\frac{d}{da_1}MSE(a_1)=\\frac{2}{n}\\sum_{i=1}^{n}x_1^{(i)}(a_{1}x_1^{(i)}−y^{(i)})$$\n",
    "\n",
    "\n",
    "For every iteration of gradient descent:\n",
    "\n",
    "* this derivative is computed using the current $a_1$ value\n",
    "* the derivative is multiplied by the learning rate ($\\alpha$): $\\alpha \\frac{d}{da_1}MSE(a_1)$\n",
    "* the result is subtracted from the current parameter value and assigned as the new parameter value: $a_{1}:=a_{1}−\\alpha \\frac{d}{da_1}MSE(a_1)$\n",
    "\n",
    "Here's what this would look like in code if we ran gradient descent for `10` iterations:\n",
    "\n",
    "```python\n",
    "a1_list = [1000]\n",
    "alpha = 10\n",
    "\n",
    "for x in range(0, 10):\n",
    "    a1 = a1_list[x]\n",
    "    deriv = derivative(a1, alpha, xi_list, yi_list)\n",
    "    a1_new = a1 - alpha*deriv\n",
    "    a1_list.append(a1_new)\n",
    "```\n",
    "\n",
    "To test your understanding, implement the `derivative()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load cleaned + feature-selected dataframe from the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "numerical_train = train.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>...</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass  Lot Frontage  Lot Area  Overall Qual  \\\n",
       "0      1  526301100           20         141.0     31770             6   \n",
       "1      2  526350040           20          80.0     11622             5   \n",
       "2      3  526351010           20          81.0     14267             6   \n",
       "3      4  526353030           20          93.0     11160             7   \n",
       "4      5  527105010           60          74.0     13830             5   \n",
       "\n",
       "   Overall Cond  Year Built  Year Remod/Add  Mas Vnr Area    ...      \\\n",
       "0             5        1960            1960         112.0    ...       \n",
       "1             6        1961            1961           0.0    ...       \n",
       "2             6        1958            1958         108.0    ...       \n",
       "3             5        1968            1968           0.0    ...       \n",
       "4             5        1997            1998           0.0    ...       \n",
       "\n",
       "   Wood Deck SF  Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  \\\n",
       "0           210             62               0           0             0   \n",
       "1           140              0               0           0           120   \n",
       "2           393             36               0           0             0   \n",
       "3             0              0               0           0             0   \n",
       "4           212             34               0           0             0   \n",
       "\n",
       "   Pool Area  Misc Val  Mo Sold  Yr Sold  SalePrice  \n",
       "0          0         0        5     2010     215000  \n",
       "1          0         0        6     2010     105000  \n",
       "2          0     12500        6     2010     172000  \n",
       "3          0         0        4     2010     244000  \n",
       "4          0         0        3     2010     189900  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "features_to_drop = ['PID', 'Year Built', 'Year Remod/Add', 'Garage Yr Blt',\n",
    "                   'Mo Sold', 'Yr Sold']\n",
    "numerical_train = numerical_train.drop(features_to_drop, axis=1) \n",
    "                                       \n",
    "null_counts = []\n",
    "for col in numerical_train.columns:\n",
    "    null_counts.append(numerical_train[col].isnull().sum())\n",
    "\n",
    "null_series = pd.Series(null_counts,\n",
    "                              index=numerical_train.columns)\n",
    "full_cols_series = null_series[null_series == 0]\n",
    "\n",
    "train_subset = train[full_cols_series.index]\n",
    "\n",
    "#####\n",
    "sorted_corrs = train_subset.corr()['SalePrice'].map(\\\n",
    "                            lambda x:abs(x)).sort_values()\n",
    "strong_corrs = train_subset[sorted_corrs[sorted_corrs > .3].index]\n",
    "\n",
    "cols_to_drop = ['Garage Cars', 'TotRms AbvGrd']\n",
    "final_corr_cols = strong_corrs.drop(cols_to_drop, axis=1)\n",
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'], axis=1)\n",
    "\n",
    "#####\n",
    "\n",
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'], axis=1)\n",
    "features = final_corr_cols.drop(['SalePrice'], axis=1).columns\n",
    "target = 'SalePrice'\n",
    "\n",
    "clean_test = test[final_corr_cols.columns].dropna(how='any',axis=0)\n",
    "\n",
    "#####\n",
    "unit_train = (train[features] - train[features].min())/(train[features].max() - train[features].min())\n",
    "sorted_vars = unit_train.var().sort_values()\n",
    "features = sorted_vars[sorted_vars > .015].index\n",
    "\n",
    "unit_test = (clean_test[features] - train[features].min())/(train[features].max() - train[features].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_train = unit_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Fireplaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.404731</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.552496</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.490591</td>\n",
       "      <td>0.158458</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.225473</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.298769</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.411790</td>\n",
       "      <td>0.588323</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.350806</td>\n",
       "      <td>0.551847</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.747849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.323925</td>\n",
       "      <td>0.395982</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.239243</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Full Bath  Garage Area  Gr Liv Area  Overall Qual  1st Flr SF  \\\n",
       "0       0.25     0.354839     0.404731      0.555556    0.552496   \n",
       "1       0.25     0.490591     0.158458      0.444444    0.225473   \n",
       "2       0.25     0.209677     0.298769      0.555556    0.411790   \n",
       "3       0.50     0.350806     0.551847      0.666667    0.747849   \n",
       "4       0.50     0.323925     0.395982      0.444444    0.239243   \n",
       "\n",
       "   Wood Deck SF  Fireplaces  \n",
       "0      0.314371    0.666667  \n",
       "1      0.209581    0.000000  \n",
       "2      0.588323    0.000000  \n",
       "3      0.000000    0.666667  \n",
       "4      0.317365    0.333333  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the data loaded.\n",
    "unit_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Fireplaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.487231</td>\n",
       "      <td>0.499028</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.251497</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.480511</td>\n",
       "      <td>0.446857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.608434</td>\n",
       "      <td>0.272455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.523522</td>\n",
       "      <td>0.610175</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.334337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.364919</td>\n",
       "      <td>0.441024</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.622165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.325731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Full Bath  Garage Area  Gr Liv Area  Overall Qual  1st Flr SF  \\\n",
       "1460        0.5     0.487231     0.499028      0.888889    0.427711   \n",
       "1461        0.5     0.480511     0.446857      0.777778    0.608434   \n",
       "1462        0.5     0.523522     0.610175      0.777778    0.334337   \n",
       "1463        0.5     0.364919     0.441024      0.666667    0.220310   \n",
       "1464        0.5     0.400538     0.622165      0.666667    0.325731   \n",
       "\n",
       "      Wood Deck SF  Fireplaces  \n",
       "1460      0.251497    0.333333  \n",
       "1461      0.272455    0.333333  \n",
       "1462      0.000000    0.333333  \n",
       "1463      0.000000    0.000000  \n",
       "1464      0.000000    0.333333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reminder\n",
    "$$\\frac{d}{da_1}MSE(a_1)=\\frac{2}{n}\\sum_{i=1}^{n}x_1^{(i)}(a_{1}x_1^{(i)}−y^{(i)})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def derivative(a1, xi_list, yi_list):\n",
    "    return 2/len(xi_list)*sum(xi_list*(a1*xi_list-yi_list))\n",
    "\n",
    "def gradient_descent(xi_list, yi_list, max_iterations, alpha, a1_initial):\n",
    "    a1_list = [a1_initial]\n",
    "\n",
    "    for i in range(0, max_iterations):\n",
    "        a1 = a1_list[i]\n",
    "        deriv = derivative(a1, xi_list, yi_list)\n",
    "        a1_new = a1 - alpha*deriv\n",
    "        a1_list.append(a1_new)\n",
    "    \n",
    "    return(a1_list)\n",
    "\n",
    "# Uncomment when ready.\n",
    "param_iterations = gradient_descent(unit_train['Gr Liv Area'], train['SalePrice'], 20, .0000003, 150)\n",
    "final_param = param_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150, 150.04282912555715, 150.08565824735126, 150.12848736538234, 150.17131647965039, 150.2141455901554, 150.2569746968974, 150.29980379987637, 150.34263289909231, 150.38546199454521, 150.42829108623511, 150.47112017416197, 150.51394925832579, 150.55677833872659, 150.59960741536437, 150.64243648823913, 150.68526555735085, 150.72809462269956, 150.77092368428524, 150.81375274210788, 150.85658179616752]\n"
     ]
    }
   ],
   "source": [
    "print(param_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.856581796\n"
     ]
    }
   ],
   "source": [
    "print(final_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Multi Parameter Gradient Descent\n",
    "\n",
    "Now that we've understood how single parameter gradient descent works, let's build some intuition for multi parameter gradient descent. Let's start by visualizing the MSE as a function of the parameter values for the following simple linear regression model:\n",
    "\n",
    "$$SalePrice=a_1∗GrLivArea+a_0$$\n",
    "\n",
    "In this screen's widget, we've generated a 3D scatter plot with:\n",
    "\n",
    "* $a_0$ on the x-axis\n",
    "* $a_1$ on the y-axis\n",
    "* $MSE$ on the z-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](img/grad_descent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Of the Cost Function\n",
    "\n",
    "In the widget from the first screen, you were able to use the parameter sliders to try to reduce the residual sum of squares (which, by proxy, also reduces the mean squared error). The [gradient](https://en.wikipedia.org/wiki/Gradient) is a **multi variable generalization of the derivative**. In the last few screens, we were concerned with minimizing the following cost function:\n",
    "\n",
    "$$MSE(a_1) = \\frac{1}{n} \\sum_{i=1}^{n} (a_1x_1^{(i)} - y^{(i)} ) ^2$$\n",
    "\n",
    "When we have 2 parameter values (**a0** and **a1**), the cost function is now a function of 2 variables, not 1:\n",
    "\n",
    "$$MSE(a_0, a_1) = \\frac{1}{n} \\sum_{i=1}^{n} (a_0 + a_1x_1^{(i)} - y^{(i)} ) ^2$$\n",
    "\n",
    "Instead of one update rule, we now need two update rules. We need one for $a_0$:\n",
    "\n",
    "$$a_0 := a_0 - \\alpha \\frac{d}{da_0} MSE(a_0, a_1)$$\n",
    "\n",
    "and one for $a_1$:\n",
    "\n",
    "$$a_1 := a_1 - \\alpha \\frac{d}{da_1} MSE(a_0, a_1)$$\n",
    "\n",
    "Earlier in this mission, we determined that $\\frac{d}{da_{1}}MSE(a_1)$ worked out to $\\frac{2}{n} \\sum_{i=1}^{n} x_1^{(i)}(a_1x_1^{(i)} - y^{(i)})$. For the multiparameter case, we need to include the additional parameter :\n",
    "\n",
    "$$\\frac{d}{da_1} MSE(a_0, a_1) = \\frac{2}{n} \\sum_{i=1}^{n} x_1^{(i)}(a_0 + a_1x_1^{(i)} - y^{(i)})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the `a0_derivative()` function, which implements the gradient for $a_0$.\n",
    "   * Even though we're working on the multiparameter case, let's keep this function name consistent with the previous one we implemented (`a1_derivative()`).\n",
    "   * You'll notice that we added the `a0` parameter to the function parameters. This is because we need both parameters for the individual parameter updates (verify this by looking at the math we explored in this screen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a1_derivative(a0, a1, xi_list, yi_list):\n",
    "    len_data = len(xi_list)\n",
    "    error = 0\n",
    "    for i in range(0, len_data):\n",
    "        error += xi_list[i]*(a0 + a1*xi_list[i] - yi_list[i])\n",
    "    deriv = 2*error/len_data\n",
    "    return deriv\n",
    "\n",
    "def a0_derivative(a0, a1, xi_list, yi_list):\n",
    "    len_data = len(xi_list)\n",
    "    error = 0\n",
    "    for i in range(0, len_data):\n",
    "        error += a0 + a1*xi_list[i] - yi_list[i]\n",
    "    deriv = 2*error/len_data\n",
    "    return deriv\n",
    "\n",
    "def gradient_descent(xi_list, yi_list, max_iterations, alpha, a1_initial, a0_initial):\n",
    "    a1_list = [a1_initial]\n",
    "    a0_list = [a0_initial]\n",
    "\n",
    "    for i in range(0, max_iterations):\n",
    "        a1 = a1_list[i]\n",
    "        a0 = a0_list[i]\n",
    "        \n",
    "        a1_deriv = a1_derivative(a0, a1, xi_list, yi_list)\n",
    "        a0_deriv = a0_derivative(a0, a1, xi_list, yi_list)\n",
    "        \n",
    "        a1_new = a1 - alpha*a1_deriv\n",
    "        a0_new = a0 - alpha*a0_deriv\n",
    "        \n",
    "        a1_list.append(a1_new)\n",
    "        a0_list.append(a0_new)\n",
    "    return(a0_list, a1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment when ready.\n",
    "a0_params, a1_params = gradient_descent(train['Gr Liv Area'], train['SalePrice'], 20, .0000003, 150, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent For Higher Dimensions\n",
    "\n",
    "What if we want to use many parameters in our model? Gradient descent actually scales to as many variables as you want. Each parameter value will need its own update rule, and it closely matches the update rule for $a_1$:\n",
    "\n",
    "$$\n",
    "a_0 := a_0 - \\alpha \\frac{d}{da_0} MSE \\\\\n",
    " a_1 := a_1 - \\alpha \\frac{d}{da_1} MSE \\\\ \n",
    " a_2 := a_2 - \\alpha \\frac{d}{da_2} MSE \\\\ \n",
    " a_3 := a_3 - \\alpha \\frac{d}{da_3} MSE \\\\ \n",
    " a_n := a_n - \\alpha \\frac{d}{da_n} MSE \\\\\n",
    "$$\n",
    "\n",
    "Besides the derivative for the MSE with respect to the intercept value ($a_0$), the derivative for other parameters are identical:\n",
    "\n",
    "$$\n",
    "\\frac{d}{da_1} MSE = \\frac{2}{n} \\sum_{i=1}^{n} x_1^{(i)}(\\hat{y}^{(i)} - y^{(i)}) \\\\  \n",
    " \\frac{d}{da_2} MSE = \\frac{2}{n} \\sum_{i=1}^{n} x_2^{(i)}(\\hat{y}^{(i)} - y^{(i)}) \\\\\n",
    " \\frac{d}{da_n} MSE = \\frac{2}{n} \\sum_{i=1}^{n} x_n^{(i)}(\\hat{y}^{(i)} - y^{(i)})  \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this mission, we explored how to find a linear regression model using the gradient descent algorithm. The main challenges with gradient descent include:\n",
    "\n",
    "* choosing good initial parameter values\n",
    "* choosing a good learning rate (falls under the domain of hyperparameter optimization)\n",
    "\n",
    "In the next mission, we'll explore a technique called OLS estimation which doesn't require any parameter or hyperparameter value selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
