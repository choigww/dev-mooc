{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec, CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary.\n",
    "\n",
    "#### 1. Texts\n",
    "* Preprocessing\n",
    "  * Lowercase, stemming, lemmatization, stopwords\n",
    "* Bag of Words\n",
    "  * Huge Vectors\n",
    "  * Ngrams can help to use local context\n",
    "  * TFiDF can be of use as postprocessing\n",
    "* Word2Vec\n",
    "  * Relatively small vectors\n",
    "  * Pretrained models\n",
    "  \n",
    "#### 2. Images\n",
    "* Features can be extracted from different layers\n",
    "* Careful choosing of pretrained network can help\n",
    "* Finetuning allows to refine pretrained models\n",
    "* Data augmentation can improve the model\n",
    "\n",
    "#### Fine-tuning and data augmentation are often used in competition where we have no other data except for images.\n",
    "\n",
    "#### There are many pretrained models for Convolutional Neural Networks and Word2Vec in the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text -> vector\n",
    "\n",
    "Vector representations of words and texts\n",
    "\n",
    "![txt-to-vector](img/txt-to-vector.png)\n",
    "\n",
    "#### Word2vec converts each word to some vector in some sophisicated space (usually serveral hundreds dimensions).\n",
    "\n",
    "![word2vec](img/word2vec.png)\n",
    "\n",
    "### Several Implementations of this embedding approach besides `Word2vec` namely `Glove` (Global Vector for word representation).\n",
    "* **Words** : Word2vec, FastText, etc.\n",
    "* **Sentences** : Doc2vec, etc.\n",
    "* There are pretrained models as well! (from Wikipedia, etc ,,,)\n",
    "\n",
    "### All pre-processing we had discussed earlier (lowercase, stemming, lemmatization, use of stopwords...) can be applied to text before training Word2vec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW and Word2vec Comparison\n",
    "\n",
    "#### Bag of Words\n",
    "* Very large vectors\n",
    "* Meaning of each value in vector is known\n",
    "\n",
    "#### Word2vec\n",
    "* Relatively small vectors\n",
    "* Values in vector can be interpreted only in some cases\n",
    "* **The words with similar meaning often have similar embeddings**\n",
    "\n",
    "#### BoW and Word2vec may result very different --- can be used together in the solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image -> vector (`CNN`)\n",
    "\n",
    "![cnn](img/cnn.png)\n",
    "\n",
    "1. Descriptors = `outputs from inner layers of neural nets`\n",
    "  * Descriptors from later layers are better to solve texts simliar to one network was trained on.\n",
    "  * In contrary, descriptors from early layers have more text independent information\n",
    "    * e.g. if your network was trained on images and data set, you may successfully use its last layer representation in some car model classification task.\n",
    "    * But if you want to use your network in some medical specific task, you probably will do better if you use an early descriptors ror even retain network from scratch.\n",
    "2. Train network from scratch\n",
    "3. Finetuning\n",
    "  * Slightly tune the model already trained on other data\n",
    "  * Especially for small data sets, better than using standalone model on descriptors or a training network from scratch\n",
    "  * Finetuning would be better than using descriptors\n",
    "    * Because it allows to tune all networks parameters and thus extract more effective image representations.\n",
    "  * Finetuning would be better than training model from scratch \n",
    "    * if we have too little data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning example\n",
    "\n",
    "The task was to classify these laid photos of roofs into one of four categories.\n",
    "\n",
    "![data-science-game-2016](img/data-science-game-2016.png)\n",
    "\n",
    "#### Finetuning VGG-16 architecture\n",
    "![cnn-tuned](img/cnn-tuned.png)\n",
    "* original size of output = `1000`\n",
    "  * remove the last layer with size of `1000`\n",
    "  * put in its place a new one with size of `4`\n",
    "  * retrain the model with very smaller rate\n",
    "    * usually about `1000` times lesser than our initial learning rate\n",
    "    \n",
    "### Another way - Using pretrained model\n",
    "* We can benefit from using model pre-trained on the similar data set\n",
    "  * Image in by itself consist of very different classes from animals to cars, from furniture to food could be found most suitable pre-trained model.\n",
    "* **We just could take model trained on places data set with pictures of buildings and houses**\n",
    "  * `fine-tune this model and further improve the result!`\n",
    "  \n",
    "\n",
    "### If you are interested in details of fine-tuning, \n",
    "you can find information about it in **almost every neural networks library** namely `Keras`, `PyTorch`, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "### Sometimes, you also want to increase the number of trianing images to train a better network.\n",
    "\n",
    "![aug](img/augmentation.png)\n",
    "![aug2](img/augmentation2.png)\n",
    "\n",
    "* **`Image Augmentation`** will be of help.\n",
    "  * Rotating `180` by degrees\n",
    "  * Rotating `90` by degrees\n",
    "    * After rotating the `Category 1` image, the image with roof oriented from up to bottom will be oriented from left to right -- `Category 2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
